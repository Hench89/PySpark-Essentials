{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark Dataframe Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 1 core(s) on appid:  local-1608542264352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://MMD5CG7432P9Y.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Review2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1697fd4b700>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Review2\").getOrCreate()\n",
    "\n",
    "# print\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "appid = spark._jsc.sc().applicationId()\n",
    "print(\"Working with\", cores, \"core(s) on appid: \",appid)\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"../Datasets/\"\n",
    "\n",
    "# how to read csv and json\n",
    "df = spark.read.csv(path+'students.csv', inferSchema=True,header=True)\n",
    "read_json = spark.read.json(path+'people.json')\n",
    "\n",
    "# how to read partquet\n",
    "read_parquet = spark.read.parquet(path+'users1.parquet')\n",
    "read_parquets = spark.read.parquet(path+'users*')\n",
    "read_some_parquets = spark.read.option(\"basePath\", path).parquet(path+'users1.parquet', path+'users2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark vs Pandas Dataframes\n",
    "Not exactly same. PySpark has limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.toPandas()\n",
    "type(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection\n",
    "Always a good idea to do this to ensure that dataframe was read in correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------------------------+--------+-----------------------+----------+-------------+-------------+\n",
      "|gender|race/ethnicity|parental level of education|   lunch|test preparation course|math score|reading score|writing score|\n",
      "+------+--------------+---------------------------+--------+-----------------------+----------+-------------+-------------+\n",
      "|female|       group B|          bachelor's degree|standard|                   none|        72|           72|           74|\n",
      "|female|       group C|               some college|standard|              completed|        69|           90|           88|\n",
      "|female|       group B|            master's degree|standard|                   none|        90|           95|           93|\n",
      "+------+--------------+---------------------------+--------+-----------------------+----------+-------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top 3\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- race/ethnicity: string (nullable = true)\n",
      " |-- parental level of education: string (nullable = true)\n",
      " |-- lunch: string (nullable = true)\n",
      " |-- test preparation course: string (nullable = true)\n",
      " |-- math score: integer (nullable = true)\n",
      " |-- reading score: integer (nullable = true)\n",
      " |-- writing score: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gender', 'string'),\n",
       " ('race/ethnicity', 'string'),\n",
       " ('parental level of education', 'string'),\n",
       " ('lunch', 'string'),\n",
       " ('test preparation course', 'string'),\n",
       " ('math score', 'int'),\n",
       " ('reading score', 'int'),\n",
       " ('writing score', 'int')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'race/ethnicity',\n",
       " 'parental level of education',\n",
       " 'lunch',\n",
       " 'test preparation course',\n",
       " 'math score',\n",
       " 'reading score',\n",
       " 'writing score']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntegerType"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data types for one column\n",
    "df.schema['reading score'].dataType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection using regular Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If your dataframe is more than just a few variables, this method is way better\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|summary|race/ethnicity|\n",
      "+-------+--------------+\n",
      "|  count|          1000|\n",
      "|   mean|          null|\n",
      "| stddev|          null|\n",
      "|    min|       group A|\n",
      "|    max|       group E|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neat \"describe\" function\n",
    "df.describe(['race/ethnicity']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+-------------+\n",
      "|summary|math score|reading score|writing score|\n",
      "+-------+----------+-------------+-------------+\n",
      "|  count|      1000|         1000|         1000|\n",
      "|    min|         0|           17|           10|\n",
      "|    25%|        57|           59|           57|\n",
      "|    75%|        77|           79|           79|\n",
      "|    max|       100|          100|          100|\n",
      "+-------+----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary function\n",
    "df.select(\"math score\", \"reading score\", \"writing score\").summary(\"count\", \"min\", \"25%\", \"75%\", \"max\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify data types as you read in datasets.\n",
    "\n",
    "Spark data types : https://spark.apache.org/docs/latest/sql-reference.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import * #StructField,StringType,IntegerType,StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField(\"age\", IntegerType(), True),StructField(\"name\", StringType(), True)]\n",
    "final_struc = StructType(fields=data_schema)\n",
    "people = spark.read.json(path+'people.json', schema=final_struc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to local\n",
    "df.write.mode(\"overwrite\").csv('write_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parquet files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace apostrophes\n",
    "from pyspark.sql.functions import *\n",
    "df = df.withColumnRenamed('parental level of education', 'ParentalLevelOfEducation')\n",
    "df = df.withColumnRenamed('test preparation course', 'TestPreparationCourse')\n",
    "df = df.withColumnRenamed('reading score', 'ReadingScore')\n",
    "df = df.withColumnRenamed('math score', 'MathScore')\n",
    "df = df.withColumnRenamed('writing score', 'WritingScore')\n",
    "\n",
    "# write parquet\n",
    "df.write.mode(\"overwrite\").parquet(\"parquet/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writting your own dataframes in Jupyter Notebooks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|     fruit|quantity|\n",
      "+----------+--------+\n",
      "|      Pear|      10|\n",
      "|    Orange|      36|\n",
      "|    Banana|     123|\n",
      "|      Kiwi|      48|\n",
      "|     Peach|      16|\n",
      "|Strawberry|       1|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "values = [('Pear',10),('Orange',36),('Banana',123),('Kiwi',48),('Peach',16),('Strawberry',1)]\n",
    "mydf = spark.createDataFrame(values,['fruit','quantity'])\n",
    "mydf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Select**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|gender|race/ethnicity|\n",
      "+------+--------------+\n",
      "|female|       group B|\n",
      "|female|       group C|\n",
      "|female|       group B|\n",
      "|  male|       group A|\n",
      "|  male|       group C|\n",
      "+------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['gender','race/ethnicity']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Order By**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------+\n",
      "|gender|race/ethnicity|MathScore|\n",
      "+------+--------------+---------+\n",
      "|female|       group C|        0|\n",
      "|female|       group B|        8|\n",
      "|female|       group B|       18|\n",
      "|female|       group B|       19|\n",
      "|female|       group C|       22|\n",
      "+------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['gender','race/ethnicity','MathScore']).orderBy(\"MathScore\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Order By Descending**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------+\n",
      "|gender|race/ethnicity|MathScore|\n",
      "+------+--------------+---------+\n",
      "|  male|       group E|      100|\n",
      "|female|       group E|      100|\n",
      "|female|       group E|      100|\n",
      "|  male|       group A|      100|\n",
      "|  male|       group D|      100|\n",
      "+------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['gender','race/ethnicity','MathScore']).orderBy(df[\"MathScore\"].desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+------------------------+------------+---------------------+---------+------------+------------+\n",
      "|gender|race/ethnicity|ParentalLevelOfEducation|       lunch|TestPreparationCourse|MathScore|ReadingScore|WritingScore|\n",
      "+------+--------------+------------------------+------------+---------------------+---------+------------+------------+\n",
      "|female|       group B|       bachelor's degree|    standard|                 none|       72|          72|          74|\n",
      "|female|       group C|            some college|    standard|            completed|       69|          90|          88|\n",
      "|female|       group B|         master's degree|    standard|                 none|       90|          95|          93|\n",
      "|  male|       group A|      associate's degree|free/reduced|                 none|       47|          57|          44|\n",
      "|  male|       group C|            some college|    standard|                 none|       76|          78|          75|\n",
      "|female|       group B|      associate's degree|    standard|                 none|       71|          83|          78|\n",
      "|female|       group B|            some college|    standard|            completed|       88|          95|          92|\n",
      "|  male|       group B|            some college|free/reduced|                 none|       40|          43|          39|\n",
      "|  male|       group D|             high school|free/reduced|            completed|       64|          64|          67|\n",
      "|female|       group B|             high school|free/reduced|                 none|       38|          60|          50|\n",
      "+------+--------------+------------------------+------------+---------------------+---------+------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+------------------------+------------+---------------------+---------+------------+------------+\n",
      "|gender|race/ethnicity|ParentalLevelOfEducation|lunch       |TestPreparationCourse|MathScore|ReadingScore|WritingScore|\n",
      "+------+--------------+------------------------+------------+---------------------+---------+------------+------------+\n",
      "|female|group B       |bachelor's degree       |standard    |none                 |72       |72          |74          |\n",
      "|female|group B       |master's degree         |standard    |none                 |90       |95          |93          |\n",
      "|male  |group A       |associate's degree      |free/reduced|none                 |47       |57          |44          |\n",
      "|female|group B       |associate's degree      |standard    |none                 |71       |83          |78          |\n",
      "|male  |group C       |associate's degree      |standard    |none                 |58       |54          |52          |\n",
      "+------+--------------+------------------------+------------+---------------------+---------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df['ParentalLevelOfEducation'].like(\"%degree%\")).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Substrings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|substring(ParentalLevelOfEducation, 1, 3)|\n",
      "+-----------------------------------------+\n",
      "|bac                                      |\n",
      "|som                                      |\n",
      "|mas                                      |\n",
      "|ass                                      |\n",
      "|som                                      |\n",
      "+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df['ParentalLevelOfEducation'].substr(1,3)).show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IS IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>ParentalLevelOfEducation</th>\n",
       "      <th>lunch</th>\n",
       "      <th>TestPreparationCourse</th>\n",
       "      <th>MathScore</th>\n",
       "      <th>ReadingScore</th>\n",
       "      <th>WritingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>71</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity ParentalLevelOfEducation         lunch  \\\n",
       "0  female        group B        bachelor's degree      standard   \n",
       "1  female        group B          master's degree      standard   \n",
       "2    male        group A       associate's degree  free/reduced   \n",
       "3  female        group B       associate's degree      standard   \n",
       "\n",
       "  TestPreparationCourse  MathScore  ReadingScore  WritingScore  \n",
       "0                  none         72            72            74  \n",
       "1                  none         90            95            93  \n",
       "2                  none         47            57            44  \n",
       "3                  none         71            83            78  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['race/ethnicity'].isin(\"group A\", 'group B')].limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Starts with Ends with**\n",
    "\n",
    "Search for a specific case - begins with \"x\" and ends with \"x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>ParentalLevelOfEducation</th>\n",
       "      <th>lunch</th>\n",
       "      <th>TestPreparationCourse</th>\n",
       "      <th>MathScore</th>\n",
       "      <th>ReadingScore</th>\n",
       "      <th>WritingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>group D</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>completed</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>67</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group E</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>completed</td>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity ParentalLevelOfEducation         lunch  \\\n",
       "0  female        group B        bachelor's degree      standard   \n",
       "1    male        group D        bachelor's degree  free/reduced   \n",
       "2  female        group C        bachelor's degree      standard   \n",
       "3    male        group E        bachelor's degree  free/reduced   \n",
       "\n",
       "  TestPreparationCourse  MathScore  ReadingScore  WritingScore  \n",
       "0                  none         72            72            74  \n",
       "1             completed         74            71            80  \n",
       "2                  none         67            69            75  \n",
       "3             completed         79            74            72  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    "    .where(df['ParentalLevelOfEducation'].startswith(\"bachelor\")) \\\n",
    "    .where(df['ParentalLevelOfEducation'].endswith(\"degree\")) \\\n",
    "    .limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Slicing**\n",
    "\n",
    "pyspark.sql.functions.slice(x, start, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|           x|\n",
      "+------------+\n",
      "|[1, 2, 3, 4]|\n",
      "|[5, 6, 7, 8]|\n",
      "+------------+\n",
      "\n",
      "+---------------+\n",
      "|Middle 2 Values|\n",
      "+---------------+\n",
      "|         [2, 3]|\n",
      "|         [6, 7]|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import slice\n",
    "\n",
    "# create and show df with arrays\n",
    "mydf = spark.createDataFrame([([1, 2, 3, 4],), ([5, 6, 7, 8],)], ['x']) \n",
    "mydf.show()\n",
    "\n",
    "# slice elements in df, from index 2, for 2 values\n",
    "mydf.select(slice(mydf.x, 2, 2).alias(\"Middle 2 Values\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to just slice your dataframe you can do this...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size before slicing: (1000, 8)\n",
      "size after slicing: (300, 5)\n"
     ]
    }
   ],
   "source": [
    "# Slice rows/cols\n",
    "mydf = df.limit(300)\n",
    "mydf = mydf.select(mydf.columns[0:5])\n",
    "\n",
    "print('size before slicing:', df.toPandas().shape)\n",
    "print('size after slicing:', mydf.toPandas().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data\n",
    "\n",
    "A large part of working with DataFrames is the ability to quickly filter out data based on conditions. Spark DataFrames are built on top of the Spark SQL platform, which means that is you already know SQL, you can quickly and easily grab that data using SQL commands, or using the DataFram methods (which is what we focus on in this course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa = spark.read.csv(path+'fifa19.csv', inferSchema=True,header=True)\n",
    "fifa.filter(\"Overall>50\").limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158023</td>\n",
       "      <td>L. Messi</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Cristiano Ronaldo</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190871</td>\n",
       "      <td>Neymar Jr</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193080</td>\n",
       "      <td>De Gea</td>\n",
       "      <td>Spain</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID               Name Nationality  Overall\n",
       "0  158023           L. Messi   Argentina       94\n",
       "1   20801  Cristiano Ronaldo    Portugal       94\n",
       "2  190871          Neymar Jr      Brazil       92\n",
       "3  193080             De Gea       Spain       91"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using SQL with .select()\n",
    "fifa.filter(\"Overall>50\").select(['ID','Name','Nationality','Overall']).limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Results as Python Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting results as Python objects: you need the \".collect()\" call at the end to \"collect\" the results\n",
    "result = fifa\\\n",
    "    .select(['Nationality','Name','Age','Overall'])\\\n",
    "    .filter(\"Overall>70\")\\\n",
    "    .orderBy(fifa[\"Overall\"].desc())\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Player Over Score 70: L. Messi\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Player Over Score 70:\",result[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows can also be called to turn into dictionaries if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nationality': 'Argentina', 'Name': 'L. Messi', 'Age': 31, 'Overall': 94}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = result[0]\n",
    "row.asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina\n",
      "L. Messi\n",
      "31\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "for item in result[0]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Options in Spark\n",
    "\n",
    "### Spark SQL\n",
    "\n",
    "Spark TempView provides two functions that allow users to run SQL queries against a Spark DataFrame:\n",
    "\n",
    "createOrReplaceTempView: The lifetime of this temporary view is tied to the [[SparkSession]] that was used to create this Dataset. It creates (or replaces if that view name already exists) a lazily evaluated \"view\" that you can then use like a hive table in Spark SQL. It does not persist to memory unless you cache the dataset that underpins the view.\n",
    "\n",
    "createGlobalTempView: The lifetime of this temporary view is tied to this Spark application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+----------+--------------------+-----+\n",
      "|      12mo|              PFA|    Region|             Offence|Count|\n",
      "+----------+-----------------+----------+--------------------+-----+\n",
      "|31/03/2003|Avon and Somerset|South West|All other theft o...|25959|\n",
      "|31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|\n",
      "|31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|\n",
      "|31/03/2003|Avon and Somerset|South West|Death or serious ...|    2|\n",
      "+----------+-----------------+----------+--------------------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(path+'rec-crime-pfa.csv', inferSchema=True,header=True)\n",
    "df = df.withColumnRenamed('12 months ending', '12mo')\n",
    "df = df.withColumnRenamed('Rolling year total number of offences', 'Count')\n",
    "df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view of the dataframe\n",
    "df.createOrReplaceTempView(\"tempview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12mo</th>\n",
       "      <th>PFA</th>\n",
       "      <th>Region</th>\n",
       "      <th>Offence</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>All other theft offences</td>\n",
       "      <td>25959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Bicycle theft</td>\n",
       "      <td>3090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Criminal damage and arson</td>\n",
       "      <td>26202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Domestic burglary</td>\n",
       "      <td>14561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Drug offences</td>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         12mo                PFA      Region                    Offence  Count\n",
       "0  31/03/2003  Avon and Somerset  South West   All other theft offences  25959\n",
       "1  31/03/2003  Avon and Somerset  South West              Bicycle theft   3090\n",
       "2  31/03/2003  Avon and Somerset  South West  Criminal damage and arson  26202\n",
       "3  31/03/2003  Avon and Somerset  South West          Domestic burglary  14561\n",
       "4  31/03/2003  Avon and Somerset  South West              Drug offences   2308"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then Query the temp view\n",
    "spark.sql(\"SELECT * FROM tempview WHERE Count > 1000\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12mo</th>\n",
       "      <th>PFA</th>\n",
       "      <th>Region</th>\n",
       "      <th>Offence</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>All other theft offences</td>\n",
       "      <td>25959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Bicycle theft</td>\n",
       "      <td>3090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Criminal damage and arson</td>\n",
       "      <td>26202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Domestic burglary</td>\n",
       "      <td>14561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Drug offences</td>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         12mo                PFA      Region                    Offence  Count\n",
       "0  31/03/2003  Avon and Somerset  South West   All other theft offences  25959\n",
       "1  31/03/2003  Avon and Somerset  South West              Bicycle theft   3090\n",
       "2  31/03/2003  Avon and Somerset  South West  Criminal damage and arson  26202\n",
       "3  31/03/2003  Avon and Somerset  South West          Domestic burglary  14561\n",
       "4  31/03/2003  Avon and Somerset  South West              Drug offences   2308"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or pass it to an object\n",
    "sql_results = spark.sql(\"SELECT * FROM tempview WHERE Count > 1000 AND Region='South West'\")\n",
    "sql_results.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fraud: CIFAS</td>\n",
       "      <td>7678981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North West</td>\n",
       "      <td>30235732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>3029117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wales</td>\n",
       "      <td>11137260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>42691902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Region     Total\n",
       "0              Fraud: CIFAS   7678981\n",
       "1                North West  30235732\n",
       "2  British Transport Police   3029117\n",
       "3                     Wales  11137260\n",
       "4                    London  42691902"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlstr = \"SELECT Region, sum(Count) AS Total FROM tempview GROUP BY Region\"\n",
    "spark.sql(sqlstr).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Transformer\n",
    "\n",
    "You also have the option to use the SQL transformer option where you can write freeform SQL scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to import SQL transformer\n",
    "from pyspark.ml.feature import SQLTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|    Region|             Offence|\n",
      "+----------+--------------------+\n",
      "|South West|All other theft o...|\n",
      "|South West|       Bicycle theft|\n",
      "|South West|Criminal damage a...|\n",
      "|South West|Death or serious ...|\n",
      "|South West|   Domestic burglary|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# __THIS__ is keyword for table used by transformer\n",
    "sqlTrans = SQLTransformer(statement=\"SELECT Region, Offence FROM __THIS__\")\n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             Offence|   Total|\n",
      "+--------------------+--------+\n",
      "|Public order offe...|10925676|\n",
      "|       Bicycle theft| 5297006|\n",
      "|Residential burglary| 1671469|\n",
      "|Violence without ...|16590158|\n",
      "|All other theft o...|30979393|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group by using sql transformer\n",
    "sqlTrans = SQLTransformer(statement=\"SELECT Offence, SUM(Count) as Total FROM __THIS__ GROUP BY Offence\")\n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupBy and Aggregate Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539.0</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787.0</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>41</td>\n",
       "      <td>-74</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595.0</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845.0</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>41</td>\n",
       "      <td>-74</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647.0</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632.0</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>41</td>\n",
       "      <td>-74</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831.0</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869.0</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>41</td>\n",
       "      <td>-74</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022.0</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192.0</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>41</td>\n",
       "      <td>-74</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              name  host_id  \\\n",
       "0  2539.0                Clean & quiet apt home by the park   2787.0   \n",
       "1  2595.0                             Skylit Midtown Castle   2845.0   \n",
       "2  3647.0               THE VILLAGE OF HARLEM....NEW YORK !   4632.0   \n",
       "3  3831.0                   Cozy Entire Floor of Brownstone   4869.0   \n",
       "4  5022.0  Entire Apt: Spacious Studio/Loft by central park   7192.0   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood latitude longitude  \\\n",
       "0         John            Brooklyn    Kensington       41       -74   \n",
       "1     Jennifer           Manhattan       Midtown       41       -74   \n",
       "2    Elisabeth           Manhattan        Harlem       41       -74   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill       41       -74   \n",
       "4        Laura           Manhattan   East Harlem       41       -74   \n",
       "\n",
       "         room_type price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room   149             1.0                9.0  2018-10-19   \n",
       "1  Entire home/apt   225             1.0               45.0  2019-05-21   \n",
       "2     Private room   150             3.0                0.0        None   \n",
       "3  Entire home/apt    89             1.0              270.0  2019-07-05   \n",
       "4  Entire home/apt    80            10.0                9.0  2018-11-19   \n",
       "\n",
       "  reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0                 0                             6.0             365.0  \n",
       "1                 0                             2.0             355.0  \n",
       "2              None                             1.0             365.0  \n",
       "3                 5                             1.0             194.0  \n",
       "4                 0                             1.0               0.0  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"host_id\", IntegerType(), True),\n",
    "    StructField(\"host_name\", StringType(), True),\n",
    "    StructField(\"neighbourhood_group\", StringType(), True),\n",
    "    StructField(\"neighbourhood\", StringType(), True),\n",
    "    StructField(\"latitude\", DecimalType(), True),\n",
    "    StructField(\"longitude\", DecimalType(), True),\n",
    "    StructField(\"room_type\", StringType(), True),\n",
    "    StructField(\"price\", DecimalType(), True),\n",
    "    StructField(\"minimum_nights\", IntegerType(), True),\n",
    "    StructField(\"number_of_reviews\", IntegerType(), True),\n",
    "    StructField(\"last_review\", DateType(), True),\n",
    "    StructField(\"reviews_per_month\", DecimalType(), True),\n",
    "    StructField(\"calculated_host_listings_count\", IntegerType(), True),\n",
    "    StructField(\"availability_365\", IntegerType(), True),\n",
    "])\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .schema(custom_schema) \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(path+'nyc_air_bnb.csv')\n",
    "df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "| neighbourhood_group|count|\n",
      "+--------------------+-----+\n",
      "|          Douglaston|    1|\n",
      "|              Queens| 5630|\n",
      "|               Nadia|    1|\n",
      "|             Midtown|    4|\n",
      "|     Jackson Heights|    2|\n",
      "|      Hell's Kitchen|    7|\n",
      "|   Greenwich Village|    2|\n",
      "|        Clinton Hill|    1|\n",
      "|  Washington Heights|    4|\n",
      "|    Ditmars Steinway|    3|\n",
      "|            Longwood|    2|\n",
      "|           Briarwood|    1|\n",
      "|         Little Neck|    1|\n",
      "|            Flushing|    3|\n",
      "|       Randall Manor|    1|\n",
      "|              Carmen|    1|\n",
      "|       East Elmhurst|    2|\n",
      "|     Upper East Side|    7|\n",
      "|                null|  185|\n",
      "|          Bath Beach|    1|\n",
      "|            Canarsie|    4|\n",
      "|              Evelyn|    1|\n",
      "|         East Harlem|    5|\n",
      "|             Astoria|    2|\n",
      "|        East Village|    4|\n",
      "|         Fort Greene|    1|\n",
      "|          Mott Haven|    5|\n",
      "|            Gramercy|    1|\n",
      "|        Williamsburg|    6|\n",
      "|                   D|    1|\n",
      "|         Throgs Neck|    1|\n",
      "|            Edgemere|    1|\n",
      "|       Cypress Hills|    2|\n",
      "|                NoHo|    2|\n",
      "|    Long Island City|    3|\n",
      "|      Queens Village|    1|\n",
      "|       East Flatbush|    1|\n",
      "|     Upper West Side|    3|\n",
      "|        West Village|    1|\n",
      "|    Brooklyn Heights|    1|\n",
      "|             Arverne|    1|\n",
      "|  Bedford-Stuyvesant|    9|\n",
      "|     Cambria Heights|    1|\n",
      "|            Brooklyn|20055|\n",
      "|         Eltingville|    1|\n",
      "|Prospect-Lefferts...|    2|\n",
      "|           Woodhaven|    3|\n",
      "|       Staten Island|  370|\n",
      "|            Woodside|    1|\n",
      "|             Midwood|    3|\n",
      "|     Stuyvesant Town|    1|\n",
      "|              Harlem|   13|\n",
      "| Springfield Gardens|    1|\n",
      "|             Maspeth|    1|\n",
      "|              Inwood|    1|\n",
      "|   Concourse Village|    1|\n",
      "|       East New York|    1|\n",
      "|       William Hakan|    1|\n",
      "|      Pelham Gardens|    2|\n",
      "|                SoHo|    1|\n",
      "|    South Ozone Park|    1|\n",
      "|                Seth|    1|\n",
      "|        Borough Park|    1|\n",
      "|           197400421|    1|\n",
      "|              Krista|    1|\n",
      "|         Murray Hill|    1|\n",
      "|       Crown Heights|    3|\n",
      "|           194716858|    1|\n",
      "|             Chelsea|    2|\n",
      "|            Bushwick|    4|\n",
      "|            Red Hook|    1|\n",
      "|            Flatbush|    2|\n",
      "|           Manhattan|21594|\n",
      "|    Prospect Heights|    1|\n",
      "|               Bronx| 1080|\n",
      "| Morningside Heights|    3|\n",
      "|          Greenpoint|    1|\n",
      "|            Elmhurst|    7|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Groupby Function with count (you can also use sum, min, max)\n",
    "df.groupBy(\"neighbourhood_group\").count().show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|neighbourhood_group|avg(price)|\n",
      "+-------------------+----------+\n",
      "|         Douglaston|    1.0000|\n",
      "|             Queens|   99.5769|\n",
      "|              Nadia|      null|\n",
      "|            Midtown|    9.0000|\n",
      "|    Jackson Heights|   16.0000|\n",
      "|     Hell's Kitchen|    1.2857|\n",
      "|  Greenwich Village|   55.5000|\n",
      "|       Clinton Hill|   14.0000|\n",
      "| Washington Heights|    2.7500|\n",
      "|   Ditmars Steinway|    3.3333|\n",
      "|           Longwood|    5.0000|\n",
      "|          Briarwood|    1.0000|\n",
      "|        Little Neck|    1.0000|\n",
      "|           Flushing|   10.3333|\n",
      "|      Randall Manor|    7.0000|\n",
      "|             Carmen|      null|\n",
      "|      East Elmhurst|    1.0000|\n",
      "|    Upper East Side|    1.5714|\n",
      "|               null|      null|\n",
      "|         Bath Beach|    2.0000|\n",
      "+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Then you can add the following aggregate functions: mean, count, min, max, sum\n",
    "df.groupBy(\"neighbourhood_group\").mean(\"price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>48887</td>\n",
       "      <td>48891</td>\n",
       "      <td>48737</td>\n",
       "      <td>38858</td>\n",
       "      <td>48887</td>\n",
       "      <td>48737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>min</td>\n",
       "      <td>-74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max</td>\n",
       "      <td>10000</td>\n",
       "      <td>1250</td>\n",
       "      <td>629</td>\n",
       "      <td>59</td>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary  price minimum_nights number_of_reviews reviews_per_month  \\\n",
       "0   count  48887          48891             48737             38858   \n",
       "1     min    -74              0                 0                 0   \n",
       "2     max  10000           1250               629                59   \n",
       "\n",
       "  calculated_host_listings_count availability_365  \n",
       "0                          48887            48737  \n",
       "1                              0                0  \n",
       "2                            365              365  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is also a pretty neat function you can use:\n",
    "summary = df.summary(\"count\", \"min\", \"25%\", \"75%\", \"max\")\n",
    "summary.toPandas()\n",
    "\n",
    "# or a prettier version\n",
    "limit_summary = df.select(\"price\",\"minimum_nights\",\"number_of_reviews\",\"last_review\",\"reviews_per_month\",\"calculated_host_listings_count\",\"availability_365\").summary(\"count\",\"min\",\"max\")\n",
    "limit_summary.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+----------+------------------+\n",
      "|count(DISTINCT neighbourhood_group)|avg(price)|stddev_samp(price)|\n",
      "+-----------------------------------+----------+------------------+\n",
      "|                                 77|  152.2230|238.54148624491813|\n",
      "+-----------------------------------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here's another way of doing it\n",
    "df.select(countDistinct(\"neighbourhood_group\"),avg('price'),stddev(\"price\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregate on the entire DataFrame without groups (shorthand for df.groupBy.agg()).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Min Price|\n",
      "+---------+\n",
      "|      -74|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df.agg(F.min(df.price).alias(\"Min Price\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Max Reviews|\n",
      "+-----------+\n",
      "|        629|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Max sales across everything\n",
    "df.agg({'number_of_reviews':'max'}).withColumnRenamed(\"max(number_of_reviews)\", \"Max Reviews\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------------+\n",
      "|    neighbourhood|max(number_of_reviews)|\n",
      "+-----------------+----------------------+\n",
      "|           Corona|                   166|\n",
      "|     Richmondtown|                    79|\n",
      "|     Prince's Bay|                    15|\n",
      "|      Westerleigh|                    17|\n",
      "|       Mill Basin|                    36|\n",
      "|         40.76199|                  null|\n",
      "|     Civic Center|                   319|\n",
      "|         40.83166|                  null|\n",
      "|       Douglaston|                    49|\n",
      "|       Mount Hope|                    80|\n",
      "|          40.7578|                  null|\n",
      "|         40.80958|                  null|\n",
      "|      Marble Hill|                    85|\n",
      "|        Rego Park|                   175|\n",
      "|         40.81225|                  null|\n",
      "|         40.76805|                  null|\n",
      "|         40.64936|                  null|\n",
      "|    Dyker Heights|                    69|\n",
      "|         40.76364|                  null|\n",
      "|Kew Gardens Hills|                    82|\n",
      "+-----------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And then if you want to group by you can do this:\n",
    "df.groupBy(\"neighbourhood\").agg({'number_of_reviews':'max'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pivot Function**\n",
    "\n",
    "Provides a two way table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------+\n",
      "|  room_type|Queens|Brooklyn|\n",
      "+-----------+------+--------+\n",
      "|Shared room|   198|     413|\n",
      "+-----------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pivot Function\n",
    "df\\\n",
    "    .filter(\"room_type='Shared room'\")\\\n",
    "    .groupBy(\"room_type\")\\\n",
    "    .pivot(\"neighbourhood_group\", [\"Queens\", \"Brooklyn\"])\\\n",
    "    .count()\\\n",
    "    .show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining and Appending DataFrames in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is TableA\n",
      "+---------+---+------+\n",
      "|     name| id| sound|\n",
      "+---------+---+------+\n",
      "|   Pirate|  1| Arrrg|\n",
      "|   Monkey|  2|  Oooo|\n",
      "|    Ninja|  3| Yaaaa|\n",
      "|Spaghetti|  4|Slurp!|\n",
      "+---------+---+------+\n",
      "\n",
      "And this is TableB\n",
      "+-----------+---+---+\n",
      "|       name| id|age|\n",
      "+-----------+---+---+\n",
      "|   Rutabaga|  1|  2|\n",
      "|     Pirate|  2| 45|\n",
      "|      Ninja|  3|102|\n",
      "|Darth Vader|  4| 87|\n",
      "+-----------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valuesA = [('Pirate',1,'Arrrg'),('Monkey',2,'Oooo'),('Ninja',3,'Yaaaa'),('Spaghetti',4,'Slurp!')]\n",
    "TableA = spark.createDataFrame(valuesA,['name','id','sound'])\n",
    "\n",
    "valuesB = [('Rutabaga',1,2),('Pirate',2,45),('Ninja',3,102),('Darth Vader',4,87)]\n",
    "TableB = spark.createDataFrame(valuesB,['name','id','age'])\n",
    "\n",
    "print(\"This is TableA\")\n",
    "TableA.show()\n",
    "print(\"And this is TableB\")\n",
    "TableB.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableA count: 4\n",
      "TableA union itself Counts: 8 3\n",
      "+---------+---+------+\n",
      "|     name| id| sound|\n",
      "+---------+---+------+\n",
      "|   Pirate|  1| Arrrg|\n",
      "|   Monkey|  2|  Oooo|\n",
      "|    Ninja|  3| Yaaaa|\n",
      "|Spaghetti|  4|Slurp!|\n",
      "+---------+---+------+\n",
      "\n",
      "+---------+---+------+\n",
      "|     name| id| sound|\n",
      "+---------+---+------+\n",
      "|   Pirate|  1| Arrrg|\n",
      "|   Monkey|  2|  Oooo|\n",
      "|    Ninja|  3| Yaaaa|\n",
      "|Spaghetti|  4|Slurp!|\n",
      "|   Pirate|  1| Arrrg|\n",
      "|   Monkey|  2|  Oooo|\n",
      "|    Ninja|  3| Yaaaa|\n",
      "|Spaghetti|  4|Slurp!|\n",
      "+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TableA count:\", TableA.count())\n",
    "\n",
    "# append table A with itself, through UNION (all)\n",
    "new_df = TableA\n",
    "df_concat = TableA.union(new_df)\n",
    "print(\"TableA union itself Counts:\", df_concat.count(), len(df_concat.columns))\n",
    "\n",
    "TableA.show(100)\n",
    "df_concat.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins!\n",
    "\n",
    "All options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Join Example\n",
      "+-----+---+-----+---+\n",
      "| name| id|sound|age|\n",
      "+-----+---+-----+---+\n",
      "|Ninja|  3|Yaaaa|102|\n",
      "+-----+---+-----+---+\n",
      "\n",
      "None\n",
      "Left Join Example\n",
      "+---------+---+------+----+\n",
      "|     name| id| sound| age|\n",
      "+---------+---+------+----+\n",
      "|   Pirate|  1| Arrrg|null|\n",
      "|    Ninja|  3| Yaaaa| 102|\n",
      "|   Monkey|  2|  Oooo|null|\n",
      "|Spaghetti|  4|Slurp!|null|\n",
      "+---------+---+------+----+\n",
      "\n",
      "None\n",
      "Conditional Left Join\n",
      "+---------+---+------+----+\n",
      "|     name| id| sound| age|\n",
      "+---------+---+------+----+\n",
      "|   Pirate|  1| Arrrg|null|\n",
      "|   Monkey|  2|  Oooo|null|\n",
      "|Spaghetti|  4|Slurp!|null|\n",
      "+---------+---+------+----+\n",
      "\n",
      "None\n",
      "Right Join\n",
      "+-----------+---+-----+---+\n",
      "|       name| id|sound|age|\n",
      "+-----------+---+-----+---+\n",
      "|Darth Vader|  4| null| 87|\n",
      "|      Ninja|  3|Yaaaa|102|\n",
      "|   Rutabaga|  1| null|  2|\n",
      "|     Pirate|  2| null| 45|\n",
      "+-----------+---+-----+---+\n",
      "\n",
      "None\n",
      "Full Outer Join\n",
      "+-----------+---+------+----+\n",
      "|       name| id| sound| age|\n",
      "+-----------+---+------+----+\n",
      "|     Pirate|  1| Arrrg|null|\n",
      "|Darth Vader|  4|  null|  87|\n",
      "|      Ninja|  3| Yaaaa| 102|\n",
      "|     Monkey|  2|  Oooo|null|\n",
      "|   Rutabaga|  1|  null|   2|\n",
      "|     Pirate|  2|  null|  45|\n",
      "|  Spaghetti|  4|Slurp!|null|\n",
      "+-----------+---+------+----+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inner_join = TableA.join(TableB, [\"name\",\"id\"],\"inner\")\n",
    "print(\"Inner Join Example:\")\n",
    "inner_join.show()\n",
    "\n",
    "left_join = TableA.join(TableB, [\"name\",\"id\"], how='left') # Could also use 'left_outer'\n",
    "print(\"Left Join Example:\")\n",
    "left_join.show()\n",
    "\n",
    "conditional_join = TableA.join(TableB, [\"name\",\"id\"], how='left').filter(TableB.name.isNull())\n",
    "print(\"Conditional Left Join:\")\n",
    "conditional_join.show()\n",
    "\n",
    "right_join = TableA.join(TableB,  [\"name\",\"id\"],how='right') # Could also use 'right_outer'\n",
    "print(\"Right Join:\")\n",
    "right_join.show()\n",
    "\n",
    "full_outer_join = TableA.join(TableB, [\"name\",\"id\"],how='full') # Could also use 'full_outer'\n",
    "print(\"Full Outer Join:\")\n",
    "full_outer_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>address</th>\n",
       "      <th>name</th>\n",
       "      <th>online_order</th>\n",
       "      <th>book_table</th>\n",
       "      <th>rate</th>\n",
       "      <th>votes</th>\n",
       "      <th>phone</th>\n",
       "      <th>location</th>\n",
       "      <th>rest_type</th>\n",
       "      <th>dish_liked</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>approx_cost(for two people)</th>\n",
       "      <th>reviews_list</th>\n",
       "      <th>menu_item</th>\n",
       "      <th>listed_in(type)</th>\n",
       "      <th>listed_in(city)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.zomato.com/bangalore/jalsa-banasha...</td>\n",
       "      <td>942, 21st Main Road, 2nd Stage, Banashankari, ...</td>\n",
       "      <td>Jalsa</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.1/5</td>\n",
       "      <td>775</td>\n",
       "      <td>080 42297555</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+91 9743772233\"</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Pasta, Lunch Buffet, Masala Papad, Paneer Laja...</td>\n",
       "      <td>North Indian, Mughlai, Chinese</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 4.0', 'RATED\\n  A beautiful place to...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  You can\\x83\\x83\\x82\\x82\\x...</td>\n",
       "      <td>('Rated 5.0'</td>\n",
       "      <td>'RATED\\n  Overdelighted by the service and fo...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.zomato.com/bangalore/spice-elephan...</td>\n",
       "      <td>2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...</td>\n",
       "      <td>Spice Elephant</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.1/5</td>\n",
       "      <td>787</td>\n",
       "      <td>080 41714161</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Momos, Lunch Buffet, Chocolate Nirvana, Thai G...</td>\n",
       "      <td>Chinese, North Indian, Thai</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 4.0', 'RATED\\n  Had been here for di...</td>\n",
       "      <td>rice was well cooked and overall was great\\n\\n...</td>\n",
       "      <td>('Rated 5.0'</td>\n",
       "      <td>'RATED\\n  This place just cool ? with good am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zomato.com/SanchurroBangalore?cont...</td>\n",
       "      <td>1112, Next to KIMS Medical College, 17th Cross...</td>\n",
       "      <td>San Churro Cafe</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8/5</td>\n",
       "      <td>918</td>\n",
       "      <td>+91 9663487993</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Cafe, Casual Dining</td>\n",
       "      <td>Churros, Cannelloni, Minestrone Soup, Hot Choc...</td>\n",
       "      <td>Cafe, Mexican, Italian</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 3.0', \"\"RATED\\n  Ambience is not tha...</td>\n",
       "      <td>('Rated 3.0'</td>\n",
       "      <td>\"\"RATED\\n \\nWent there for a quick bite with ...</td>\n",
       "      <td>pasta churros and lasagne.\\n\\nNachos were pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.zomato.com/bangalore/addhuri-udupi...</td>\n",
       "      <td>1st Floor, Annakuteera, 3rd Stage, Banashankar...</td>\n",
       "      <td>Addhuri Udupi Bhojana</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.7/5</td>\n",
       "      <td>88</td>\n",
       "      <td>+91 9620009302</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Quick Bites</td>\n",
       "      <td>Masala Dosa</td>\n",
       "      <td>South Indian, North Indian</td>\n",
       "      <td>300</td>\n",
       "      <td>\"[('Rated 4.0', \"\"RATED\\n  Great food and prop...</td>\n",
       "      <td>('Rated 2.0'</td>\n",
       "      <td>'RATED\\n  Reached the place at 3pm on Saturda...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.zomato.com/bangalore/jalsa-banasha...   \n",
       "1                                    +91 9743772233\"   \n",
       "2  https://www.zomato.com/bangalore/spice-elephan...   \n",
       "3  https://www.zomato.com/SanchurroBangalore?cont...   \n",
       "4  https://www.zomato.com/bangalore/addhuri-udupi...   \n",
       "\n",
       "                                             address                   name  \\\n",
       "0  942, 21st Main Road, 2nd Stage, Banashankari, ...                  Jalsa   \n",
       "1                                       Banashankari          Casual Dining   \n",
       "2  2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...         Spice Elephant   \n",
       "3  1112, Next to KIMS Medical College, 17th Cross...        San Churro Cafe   \n",
       "4  1st Floor, Annakuteera, 3rd Stage, Banashankar...  Addhuri Udupi Bhojana   \n",
       "\n",
       "                                        online_order  \\\n",
       "0                                                Yes   \n",
       "1  Pasta, Lunch Buffet, Masala Papad, Paneer Laja...   \n",
       "2                                                Yes   \n",
       "3                                                Yes   \n",
       "4                                                 No   \n",
       "\n",
       "                       book_table   rate  \\\n",
       "0                             Yes  4.1/5   \n",
       "1  North Indian, Mughlai, Chinese    800   \n",
       "2                              No  4.1/5   \n",
       "3                              No  3.8/5   \n",
       "4                              No  3.7/5   \n",
       "\n",
       "                                               votes           phone  \\\n",
       "0                                                775    080 42297555   \n",
       "1  \"[('Rated 4.0', 'RATED\\n  A beautiful place to...    ('Rated 4.0'   \n",
       "2                                                787    080 41714161   \n",
       "3                                                918  +91 9663487993   \n",
       "4                                                 88  +91 9620009302   \n",
       "\n",
       "                                            location            rest_type  \\\n",
       "0                                               None                 None   \n",
       "1   'RATED\\n  You can\\x83\\x83\\x82\\x82\\x...         ('Rated 5.0'   \n",
       "2                                       Banashankari        Casual Dining   \n",
       "3                                       Banashankari  Cafe, Casual Dining   \n",
       "4                                       Banashankari          Quick Bites   \n",
       "\n",
       "                                          dish_liked  \\\n",
       "0                                               None   \n",
       "1   'RATED\\n  Overdelighted by the service and fo...   \n",
       "2  Momos, Lunch Buffet, Chocolate Nirvana, Thai G...   \n",
       "3  Churros, Cannelloni, Minestrone Soup, Hot Choc...   \n",
       "4                                        Masala Dosa   \n",
       "\n",
       "                      cuisines  \\\n",
       "0                         None   \n",
       "1                 ('Rated 4.0'   \n",
       "2  Chinese, North Indian, Thai   \n",
       "3       Cafe, Mexican, Italian   \n",
       "4   South Indian, North Indian   \n",
       "\n",
       "                         approx_cost(for two people)  \\\n",
       "0                                               None   \n",
       "1   'RATED\\n  The place is nice and comfortable. ...   \n",
       "2                                                800   \n",
       "3                                                800   \n",
       "4                                                300   \n",
       "\n",
       "                                        reviews_list  \\\n",
       "0                                               None   \n",
       "1                                       ('Rated 4.0'   \n",
       "2  \"[('Rated 4.0', 'RATED\\n  Had been here for di...   \n",
       "3  \"[('Rated 3.0', \"\"RATED\\n  Ambience is not tha...   \n",
       "4  \"[('Rated 4.0', \"\"RATED\\n  Great food and prop...   \n",
       "\n",
       "                                           menu_item  \\\n",
       "0                                               None   \n",
       "1   'RATED\\n  The place is nice and comfortable. ...   \n",
       "2  rice was well cooked and overall was great\\n\\n...   \n",
       "3                                       ('Rated 3.0'   \n",
       "4                                       ('Rated 2.0'   \n",
       "\n",
       "                                     listed_in(type)  \\\n",
       "0                                               None   \n",
       "1                                       ('Rated 4.0'   \n",
       "2                                       ('Rated 5.0'   \n",
       "3   \"\"RATED\\n \\nWent there for a quick bite with ...   \n",
       "4   'RATED\\n  Reached the place at 3pm on Saturda...   \n",
       "\n",
       "                                     listed_in(city)  \n",
       "0                                               None  \n",
       "1   'RATED\\n  The place is nice and comfortable. ...  \n",
       "2   'RATED\\n  This place just cool ? with good am...  \n",
       "3   pasta churros and lasagne.\\n\\nNachos were pat...  \n",
       "4                                       ('Rated 4.0'  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(path+'zomato.csv', inferSchema=True,header=True)\n",
    "#df = df.withColumnRenamed('12 months ending', '12mo')\n",
    "df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                name|cuisines|\n",
      "+--------------------+--------+\n",
      "|               Jalsa|    null|\n",
      "|       Grand Village|    null|\n",
      "|       Casual Dining|    null|\n",
      "|     Timepass Dinner|    null|\n",
      "|       Casual Dining|    null|\n",
      "|Rosewood Internat...|    null|\n",
      "|       Casual Dining|    null|\n",
      "|              Onesta|    null|\n",
      "|      Penthouse Cafe|    null|\n",
      "|           Smacznego|    null|\n",
      "|Caf...|    null|\n",
      "|       Cafe Vivacity|    null|\n",
      "|        Catch-up-ino|    null|\n",
      "|    Kirthi's Biryani|    null|\n",
      "|    The Vintage Cafe|    null|\n",
      "|        My Tea House|    null|\n",
      "|    Srinathji's Cafe|    null|\n",
      "| Casual Dining, Cafe|    null|\n",
      "|     Behrouz Biryani|    null|\n",
      "|     Szechuan Dragon|    null|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find where cuisines is null\n",
    "df.filter(df.cuisines.isNull()).select(['name','cuisines']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Data Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>address</th>\n",
       "      <th>name</th>\n",
       "      <th>online_order</th>\n",
       "      <th>book_table</th>\n",
       "      <th>rate</th>\n",
       "      <th>votes</th>\n",
       "      <th>phone</th>\n",
       "      <th>location</th>\n",
       "      <th>rest_type</th>\n",
       "      <th>dish_liked</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>approx_cost(for two people)</th>\n",
       "      <th>reviews_list</th>\n",
       "      <th>menu_item</th>\n",
       "      <th>listed_in(type)</th>\n",
       "      <th>listed_in(city)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>8111</td>\n",
       "      <td>2</td>\n",
       "      <td>7775</td>\n",
       "      <td>0</td>\n",
       "      <td>1227</td>\n",
       "      <td>20054</td>\n",
       "      <td>20165</td>\n",
       "      <td>46841</td>\n",
       "      <td>27305</td>\n",
       "      <td>28143</td>\n",
       "      <td>28185</td>\n",
       "      <td>28611</td>\n",
       "      <td>28983</td>\n",
       "      <td>29344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>65.3</td>\n",
       "      <td>38.1</td>\n",
       "      <td>39.2</td>\n",
       "      <td>39.3</td>\n",
       "      <td>39.9</td>\n",
       "      <td>40.4</td>\n",
       "      <td>40.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url address name online_order book_table  rate votes phone location  \\\n",
       "0    0       0   85         8111          2  7775     0  1227    20054   \n",
       "1  0.0     0.0  0.1         11.3        0.0  10.8   0.0   1.7     28.0   \n",
       "\n",
       "  rest_type dish_liked cuisines approx_cost(for two people) reviews_list  \\\n",
       "0     20165      46841    27305                       28143        28185   \n",
       "1      28.1       65.3     38.1                        39.2         39.3   \n",
       "\n",
       "  menu_item listed_in(type) listed_in(city)  \n",
       "0     28611           28983           29344  \n",
       "1      39.9            40.4            40.9  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "nulls = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "percent = df.select([format_number(((count(when(isnan(c) | col(c).isNull(), c))/df.count())*100),1).alias(c) for c in df.columns])\n",
    "result = nulls.union(percent)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------+\n",
      "|Column_With_Null_Value|Null_Values_Count|\n",
      "+----------------------+-----------------+\n",
      "|                  name|               85|\n",
      "|          online_order|             8111|\n",
      "|            book_table|                2|\n",
      "|                  rate|             7775|\n",
      "|                 phone|             1227|\n",
      "|              location|            20054|\n",
      "|             rest_type|            20165|\n",
      "|            dish_liked|            46841|\n",
      "|              cuisines|            27305|\n",
      "|  approx_cost(for t...|            28143|\n",
      "|          reviews_list|            28185|\n",
      "|             menu_item|            28611|\n",
      "|       listed_in(type)|            28983|\n",
      "|       listed_in(city)|            29344|\n",
      "+----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "def null_value_count(df):\n",
    "    null_columns_counts = []\n",
    "    numRows = df.count()\n",
    "    for k in df.columns:\n",
    "        nullRows = df.where(col(k).isNull()).count()\n",
    "        if(nullRows > 0):\n",
    "            temp = k,nullRows\n",
    "            null_columns_counts.append(temp)\n",
    "    return(null_columns_counts)\n",
    "\n",
    "null_columns_count_list = null_value_count(df)\n",
    "spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop all missing data**\n",
    "\n",
    "PySpark has a really handy .na function for working with missing data. The drop command has the following parameters:\n",
    "\n",
    "    df.na.drop(how='any', thresh=None, subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>address</th>\n",
       "      <th>name</th>\n",
       "      <th>online_order</th>\n",
       "      <th>book_table</th>\n",
       "      <th>rate</th>\n",
       "      <th>votes</th>\n",
       "      <th>phone</th>\n",
       "      <th>location</th>\n",
       "      <th>rest_type</th>\n",
       "      <th>dish_liked</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>approx_cost(for two people)</th>\n",
       "      <th>reviews_list</th>\n",
       "      <th>menu_item</th>\n",
       "      <th>listed_in(type)</th>\n",
       "      <th>listed_in(city)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+91 9743772233\"</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Pasta, Lunch Buffet, Masala Papad, Paneer Laja...</td>\n",
       "      <td>North Indian, Mughlai, Chinese</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 4.0', 'RATED\\n  A beautiful place to...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  You can\\x83\\x83\\x82\\x82\\x...</td>\n",
       "      <td>('Rated 5.0'</td>\n",
       "      <td>'RATED\\n  Overdelighted by the service and fo...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.zomato.com/bangalore/spice-elephan...</td>\n",
       "      <td>2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...</td>\n",
       "      <td>Spice Elephant</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.1/5</td>\n",
       "      <td>787</td>\n",
       "      <td>080 41714161</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Momos, Lunch Buffet, Chocolate Nirvana, Thai G...</td>\n",
       "      <td>Chinese, North Indian, Thai</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 4.0', 'RATED\\n  Had been here for di...</td>\n",
       "      <td>rice was well cooked and overall was great\\n\\n...</td>\n",
       "      <td>('Rated 5.0'</td>\n",
       "      <td>'RATED\\n  This place just cool ? with good am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.zomato.com/SanchurroBangalore?cont...</td>\n",
       "      <td>1112, Next to KIMS Medical College, 17th Cross...</td>\n",
       "      <td>San Churro Cafe</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8/5</td>\n",
       "      <td>918</td>\n",
       "      <td>+91 9663487993</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Cafe, Casual Dining</td>\n",
       "      <td>Churros, Cannelloni, Minestrone Soup, Hot Choc...</td>\n",
       "      <td>Cafe, Mexican, Italian</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 3.0', \"\"RATED\\n  Ambience is not tha...</td>\n",
       "      <td>('Rated 3.0'</td>\n",
       "      <td>\"\"RATED\\n \\nWent there for a quick bite with ...</td>\n",
       "      <td>pasta churros and lasagne.\\n\\nNachos were pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zomato.com/bangalore/addhuri-udupi...</td>\n",
       "      <td>1st Floor, Annakuteera, 3rd Stage, Banashankar...</td>\n",
       "      <td>Addhuri Udupi Bhojana</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.7/5</td>\n",
       "      <td>88</td>\n",
       "      <td>+91 9620009302</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Quick Bites</td>\n",
       "      <td>Masala Dosa</td>\n",
       "      <td>South Indian, North Indian</td>\n",
       "      <td>300</td>\n",
       "      <td>\"[('Rated 4.0', \"\"RATED\\n  Great food and prop...</td>\n",
       "      <td>('Rated 2.0'</td>\n",
       "      <td>'RATED\\n  Reached the place at 3pm on Saturda...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0                                    +91 9743772233\"   \n",
       "1  https://www.zomato.com/bangalore/spice-elephan...   \n",
       "2  https://www.zomato.com/SanchurroBangalore?cont...   \n",
       "3  https://www.zomato.com/bangalore/addhuri-udupi...   \n",
       "\n",
       "                                             address                   name  \\\n",
       "0                                       Banashankari          Casual Dining   \n",
       "1  2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...         Spice Elephant   \n",
       "2  1112, Next to KIMS Medical College, 17th Cross...        San Churro Cafe   \n",
       "3  1st Floor, Annakuteera, 3rd Stage, Banashankar...  Addhuri Udupi Bhojana   \n",
       "\n",
       "                                        online_order  \\\n",
       "0  Pasta, Lunch Buffet, Masala Papad, Paneer Laja...   \n",
       "1                                                Yes   \n",
       "2                                                Yes   \n",
       "3                                                 No   \n",
       "\n",
       "                       book_table   rate  \\\n",
       "0  North Indian, Mughlai, Chinese    800   \n",
       "1                              No  4.1/5   \n",
       "2                              No  3.8/5   \n",
       "3                              No  3.7/5   \n",
       "\n",
       "                                               votes           phone  \\\n",
       "0  \"[('Rated 4.0', 'RATED\\n  A beautiful place to...    ('Rated 4.0'   \n",
       "1                                                787    080 41714161   \n",
       "2                                                918  +91 9663487993   \n",
       "3                                                 88  +91 9620009302   \n",
       "\n",
       "                                            location            rest_type  \\\n",
       "0   'RATED\\n  You can\\x83\\x83\\x82\\x82\\x...         ('Rated 5.0'   \n",
       "1                                       Banashankari        Casual Dining   \n",
       "2                                       Banashankari  Cafe, Casual Dining   \n",
       "3                                       Banashankari          Quick Bites   \n",
       "\n",
       "                                          dish_liked  \\\n",
       "0   'RATED\\n  Overdelighted by the service and fo...   \n",
       "1  Momos, Lunch Buffet, Chocolate Nirvana, Thai G...   \n",
       "2  Churros, Cannelloni, Minestrone Soup, Hot Choc...   \n",
       "3                                        Masala Dosa   \n",
       "\n",
       "                      cuisines  \\\n",
       "0                 ('Rated 4.0'   \n",
       "1  Chinese, North Indian, Thai   \n",
       "2       Cafe, Mexican, Italian   \n",
       "3   South Indian, North Indian   \n",
       "\n",
       "                         approx_cost(for two people)  \\\n",
       "0   'RATED\\n  The place is nice and comfortable. ...   \n",
       "1                                                800   \n",
       "2                                                800   \n",
       "3                                                300   \n",
       "\n",
       "                                        reviews_list  \\\n",
       "0                                       ('Rated 4.0'   \n",
       "1  \"[('Rated 4.0', 'RATED\\n  Had been here for di...   \n",
       "2  \"[('Rated 3.0', \"\"RATED\\n  Ambience is not tha...   \n",
       "3  \"[('Rated 4.0', \"\"RATED\\n  Great food and prop...   \n",
       "\n",
       "                                           menu_item  \\\n",
       "0   'RATED\\n  The place is nice and comfortable. ...   \n",
       "1  rice was well cooked and overall was great\\n\\n...   \n",
       "2                                       ('Rated 3.0'   \n",
       "3                                       ('Rated 2.0'   \n",
       "\n",
       "                                     listed_in(type)  \\\n",
       "0                                       ('Rated 4.0'   \n",
       "1                                       ('Rated 5.0'   \n",
       "2   \"\"RATED\\n \\nWent there for a quick bite with ...   \n",
       "3   'RATED\\n  Reached the place at 3pm on Saturda...   \n",
       "\n",
       "                                     listed_in(city)  \n",
       "0   'RATED\\n  The place is nice and comfortable. ...  \n",
       "1   'RATED\\n  This place just cool ? with good am...  \n",
       "2   pasta churros and lasagne.\\n\\nNachos were pat...  \n",
       "3                                       ('Rated 4.0'  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.na.drop().limit(4).toPandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows Dropped: 52402\n",
      "Percentage of Rows Dropped 0.7305450996793531\n"
     ]
    }
   ],
   "source": [
    "# Of course you will want to know how many rows that affected before you actually execute it..\n",
    "og_len = df.count()\n",
    "drop_len = df.na.drop().count()\n",
    "print(\"Total Rows Dropped:\",og_len-drop_len)\n",
    "print(\"Percentage of Rows Dropped\", (og_len-drop_len)/og_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows Dropped: 1669\n",
      "Percentage of Rows Dropped 0.0232678098424648\n"
     ]
    }
   ],
   "source": [
    "# Drop rows that have at least 8 NON-null values\n",
    "og_len = df.count()\n",
    "drop_len = df.na.drop(thresh=8).count()\n",
    "print(\"Total Rows Dropped:\",og_len-drop_len)\n",
    "print(\"Percentage of Rows Dropped\", (og_len-drop_len)/og_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows Dropped: 7775\n",
      "Percentage of Rows Dropped 0.10839258329848041\n"
     ]
    }
   ],
   "source": [
    "# Only drop the rows whose values in the sales column are null\n",
    "og_len = df.count()\n",
    "drop_len = df.na.drop(subset=[\"rate\"]).count() \n",
    "print(\"Total Rows Dropped:\",og_len-drop_len)\n",
    "print(\"Percentage of Rows Dropped\", (og_len-drop_len)/og_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows Dropped: 7775\n",
      "Percentage of Rows Dropped 0.10839258329848041\n"
     ]
    }
   ],
   "source": [
    "# Another way to do the above\n",
    "og_len = df.count()\n",
    "drop_len = df.filter(df.rate.isNotNull()).count() \n",
    "print(\"Total Rows Dropped:\",og_len-drop_len)\n",
    "print(\"Percentage of Rows Dropped\", (og_len-drop_len)/og_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows Dropped: 0\n",
      "Percentage of Rows Dropped 0.0\n"
     ]
    }
   ],
   "source": [
    "# Drop a row only if ALL its values are null.\n",
    "og_len = df.count()\n",
    "drop_len = df.na.drop(how='all').count() \n",
    "print(\"Total Rows Dropped:\",og_len-drop_len)\n",
    "print(\"Percentage of Rows Dropped\", (og_len-drop_len)/og_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the missing values\n",
    "\n",
    "We can also fill the missing values with new values. If you have multiple nulls across multiple data types, Spark is actually smart enough to match up the data types. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>address</th>\n",
       "      <th>name</th>\n",
       "      <th>online_order</th>\n",
       "      <th>book_table</th>\n",
       "      <th>rate</th>\n",
       "      <th>votes</th>\n",
       "      <th>phone</th>\n",
       "      <th>location</th>\n",
       "      <th>rest_type</th>\n",
       "      <th>dish_liked</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>approx_cost(for two people)</th>\n",
       "      <th>reviews_list</th>\n",
       "      <th>menu_item</th>\n",
       "      <th>listed_in(type)</th>\n",
       "      <th>listed_in(city)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.zomato.com/bangalore/jalsa-banasha...</td>\n",
       "      <td>942, 21st Main Road, 2nd Stage, Banashankari, ...</td>\n",
       "      <td>Jalsa</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.1/5</td>\n",
       "      <td>775</td>\n",
       "      <td>080 42297555</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+91 9743772233\"</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Pasta, Lunch Buffet, Masala Papad, Paneer Laja...</td>\n",
       "      <td>North Indian, Mughlai, Chinese</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 4.0', 'RATED\\n  A beautiful place to...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  You can\\x83\\x83\\x82\\x82\\x...</td>\n",
       "      <td>('Rated 5.0'</td>\n",
       "      <td>'RATED\\n  Overdelighted by the service and fo...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.zomato.com/bangalore/spice-elephan...</td>\n",
       "      <td>2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...</td>\n",
       "      <td>Spice Elephant</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.1/5</td>\n",
       "      <td>787</td>\n",
       "      <td>080 41714161</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Momos, Lunch Buffet, Chocolate Nirvana, Thai G...</td>\n",
       "      <td>Chinese, North Indian, Thai</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 4.0', 'RATED\\n  Had been here for di...</td>\n",
       "      <td>rice was well cooked and overall was great\\n\\n...</td>\n",
       "      <td>('Rated 5.0'</td>\n",
       "      <td>'RATED\\n  This place just cool ? with good am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zomato.com/SanchurroBangalore?cont...</td>\n",
       "      <td>1112, Next to KIMS Medical College, 17th Cross...</td>\n",
       "      <td>San Churro Cafe</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8/5</td>\n",
       "      <td>918</td>\n",
       "      <td>+91 9663487993</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Cafe, Casual Dining</td>\n",
       "      <td>Churros, Cannelloni, Minestrone Soup, Hot Choc...</td>\n",
       "      <td>Cafe, Mexican, Italian</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 3.0', \"\"RATED\\n  Ambience is not tha...</td>\n",
       "      <td>('Rated 3.0'</td>\n",
       "      <td>\"\"RATED\\n \\nWent there for a quick bite with ...</td>\n",
       "      <td>pasta churros and lasagne.\\n\\nNachos were pat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.zomato.com/bangalore/jalsa-banasha...   \n",
       "1                                    +91 9743772233\"   \n",
       "2  https://www.zomato.com/bangalore/spice-elephan...   \n",
       "3  https://www.zomato.com/SanchurroBangalore?cont...   \n",
       "\n",
       "                                             address             name  \\\n",
       "0  942, 21st Main Road, 2nd Stage, Banashankari, ...            Jalsa   \n",
       "1                                       Banashankari    Casual Dining   \n",
       "2  2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...   Spice Elephant   \n",
       "3  1112, Next to KIMS Medical College, 17th Cross...  San Churro Cafe   \n",
       "\n",
       "                                        online_order  \\\n",
       "0                                                Yes   \n",
       "1  Pasta, Lunch Buffet, Masala Papad, Paneer Laja...   \n",
       "2                                                Yes   \n",
       "3                                                Yes   \n",
       "\n",
       "                       book_table   rate  \\\n",
       "0                             Yes  4.1/5   \n",
       "1  North Indian, Mughlai, Chinese    800   \n",
       "2                              No  4.1/5   \n",
       "3                              No  3.8/5   \n",
       "\n",
       "                                               votes           phone  \\\n",
       "0                                                775    080 42297555   \n",
       "1  \"[('Rated 4.0', 'RATED\\n  A beautiful place to...    ('Rated 4.0'   \n",
       "2                                                787    080 41714161   \n",
       "3                                                918  +91 9663487993   \n",
       "\n",
       "                                            location            rest_type  \\\n",
       "0                                            MISSING              MISSING   \n",
       "1   'RATED\\n  You can\\x83\\x83\\x82\\x82\\x...         ('Rated 5.0'   \n",
       "2                                       Banashankari        Casual Dining   \n",
       "3                                       Banashankari  Cafe, Casual Dining   \n",
       "\n",
       "                                          dish_liked  \\\n",
       "0                                            MISSING   \n",
       "1   'RATED\\n  Overdelighted by the service and fo...   \n",
       "2  Momos, Lunch Buffet, Chocolate Nirvana, Thai G...   \n",
       "3  Churros, Cannelloni, Minestrone Soup, Hot Choc...   \n",
       "\n",
       "                      cuisines  \\\n",
       "0                      MISSING   \n",
       "1                 ('Rated 4.0'   \n",
       "2  Chinese, North Indian, Thai   \n",
       "3       Cafe, Mexican, Italian   \n",
       "\n",
       "                         approx_cost(for two people)  \\\n",
       "0                                            MISSING   \n",
       "1   'RATED\\n  The place is nice and comfortable. ...   \n",
       "2                                                800   \n",
       "3                                                800   \n",
       "\n",
       "                                        reviews_list  \\\n",
       "0                                            MISSING   \n",
       "1                                       ('Rated 4.0'   \n",
       "2  \"[('Rated 4.0', 'RATED\\n  Had been here for di...   \n",
       "3  \"[('Rated 3.0', \"\"RATED\\n  Ambience is not tha...   \n",
       "\n",
       "                                           menu_item  \\\n",
       "0                                            MISSING   \n",
       "1   'RATED\\n  The place is nice and comfortable. ...   \n",
       "2  rice was well cooked and overall was great\\n\\n...   \n",
       "3                                       ('Rated 3.0'   \n",
       "\n",
       "                                     listed_in(type)  \\\n",
       "0                                            MISSING   \n",
       "1                                       ('Rated 4.0'   \n",
       "2                                       ('Rated 5.0'   \n",
       "3   \"\"RATED\\n \\nWent there for a quick bite with ...   \n",
       "\n",
       "                                     listed_in(city)  \n",
       "0                                            MISSING  \n",
       "1   'RATED\\n  The place is nice and comfortable. ...  \n",
       "2   'RATED\\n  This place just cool ? with good am...  \n",
       "3   pasta churros and lasagne.\\n\\nNachos were pat...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill all nulls values with one common value (character value)\n",
    "df.na.fill('MISSING').limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>address</th>\n",
       "      <th>name</th>\n",
       "      <th>online_order</th>\n",
       "      <th>book_table</th>\n",
       "      <th>rate</th>\n",
       "      <th>votes</th>\n",
       "      <th>phone</th>\n",
       "      <th>location</th>\n",
       "      <th>rest_type</th>\n",
       "      <th>dish_liked</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>approx_cost(for two people)</th>\n",
       "      <th>reviews_list</th>\n",
       "      <th>menu_item</th>\n",
       "      <th>listed_in(type)</th>\n",
       "      <th>listed_in(city)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.zomato.com/bangalore/jalsa-banasha...</td>\n",
       "      <td>942, 21st Main Road, 2nd Stage, Banashankari, ...</td>\n",
       "      <td>Jalsa</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.1/5</td>\n",
       "      <td>775</td>\n",
       "      <td>080 42297555</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+91 9743772233\"</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Pasta, Lunch Buffet, Masala Papad, Paneer Laja...</td>\n",
       "      <td>North Indian, Mughlai, Chinese</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 4.0', 'RATED\\n  A beautiful place to...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  You can\\x83\\x83\\x82\\x82\\x...</td>\n",
       "      <td>('Rated 5.0'</td>\n",
       "      <td>'RATED\\n  Overdelighted by the service and fo...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.zomato.com/bangalore/spice-elephan...</td>\n",
       "      <td>2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...</td>\n",
       "      <td>Spice Elephant</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.1/5</td>\n",
       "      <td>787</td>\n",
       "      <td>080 41714161</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Momos, Lunch Buffet, Chocolate Nirvana, Thai G...</td>\n",
       "      <td>Chinese, North Indian, Thai</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 4.0', 'RATED\\n  Had been here for di...</td>\n",
       "      <td>rice was well cooked and overall was great\\n\\n...</td>\n",
       "      <td>('Rated 5.0'</td>\n",
       "      <td>'RATED\\n  This place just cool ? with good am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zomato.com/SanchurroBangalore?cont...</td>\n",
       "      <td>1112, Next to KIMS Medical College, 17th Cross...</td>\n",
       "      <td>San Churro Cafe</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8/5</td>\n",
       "      <td>918</td>\n",
       "      <td>+91 9663487993</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Cafe, Casual Dining</td>\n",
       "      <td>Churros, Cannelloni, Minestrone Soup, Hot Choc...</td>\n",
       "      <td>Cafe, Mexican, Italian</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 3.0', \"\"RATED\\n  Ambience is not tha...</td>\n",
       "      <td>('Rated 3.0'</td>\n",
       "      <td>\"\"RATED\\n \\nWent there for a quick bite with ...</td>\n",
       "      <td>pasta churros and lasagne.\\n\\nNachos were pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.zomato.com/bangalore/addhuri-udupi...</td>\n",
       "      <td>1st Floor, Annakuteera, 3rd Stage, Banashankar...</td>\n",
       "      <td>Addhuri Udupi Bhojana</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.7/5</td>\n",
       "      <td>88</td>\n",
       "      <td>+91 9620009302</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Quick Bites</td>\n",
       "      <td>Masala Dosa</td>\n",
       "      <td>South Indian, North Indian</td>\n",
       "      <td>300</td>\n",
       "      <td>\"[('Rated 4.0', \"\"RATED\\n  Great food and prop...</td>\n",
       "      <td>('Rated 2.0'</td>\n",
       "      <td>'RATED\\n  Reached the place at 3pm on Saturda...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.zomato.com/bangalore/grand-village...</td>\n",
       "      <td>10, 3rd Floor, Lakshmi Associates, Gandhi Baza...</td>\n",
       "      <td>Grand Village</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8/5</td>\n",
       "      <td>166</td>\n",
       "      <td>+91 8026612447</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>+91 9901210005\"</td>\n",
       "      <td>Basavanagudi</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Panipuri, Gol Gappe</td>\n",
       "      <td>North Indian, Rajasthani</td>\n",
       "      <td>600</td>\n",
       "      <td>[('Rated 4.0', 'RATED\\n  Very good restaurant ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.zomato.com/bangalore/timepass-dinn...</td>\n",
       "      <td>37, 5-1, 4th Floor, Bosco Court, Gandhi Bazaar...</td>\n",
       "      <td>Timepass Dinner</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8/5</td>\n",
       "      <td>286</td>\n",
       "      <td>+91 9980040002</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>+91 9980063005\"</td>\n",
       "      <td>Basavanagudi</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Onion Rings, Pasta, Kadhai Paneer, Salads, Sal...</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>600</td>\n",
       "      <td>[('Rated 3.0', 'RATED\\n  Food 3/5\\nAmbience 3/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.zomato.com/bangalore/rosewood-inte...</td>\n",
       "      <td>19/1, New Timberyard Layout, Beside Satellite ...</td>\n",
       "      <td>Rosewood International Hotel - Bar &amp; Restaurant</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.6/5</td>\n",
       "      <td>8</td>\n",
       "      <td>+91 9731716688</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.zomato.com/bangalore/jalsa-banasha...   \n",
       "1                                    +91 9743772233\"   \n",
       "2  https://www.zomato.com/bangalore/spice-elephan...   \n",
       "3  https://www.zomato.com/SanchurroBangalore?cont...   \n",
       "4  https://www.zomato.com/bangalore/addhuri-udupi...   \n",
       "5  https://www.zomato.com/bangalore/grand-village...   \n",
       "6                                    +91 9901210005\"   \n",
       "7  https://www.zomato.com/bangalore/timepass-dinn...   \n",
       "8                                    +91 9980063005\"   \n",
       "9  https://www.zomato.com/bangalore/rosewood-inte...   \n",
       "\n",
       "                                             address  \\\n",
       "0  942, 21st Main Road, 2nd Stage, Banashankari, ...   \n",
       "1                                       Banashankari   \n",
       "2  2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...   \n",
       "3  1112, Next to KIMS Medical College, 17th Cross...   \n",
       "4  1st Floor, Annakuteera, 3rd Stage, Banashankar...   \n",
       "5  10, 3rd Floor, Lakshmi Associates, Gandhi Baza...   \n",
       "6                                       Basavanagudi   \n",
       "7  37, 5-1, 4th Floor, Bosco Court, Gandhi Bazaar...   \n",
       "8                                       Basavanagudi   \n",
       "9  19/1, New Timberyard Layout, Beside Satellite ...   \n",
       "\n",
       "                                              name  \\\n",
       "0                                            Jalsa   \n",
       "1                                    Casual Dining   \n",
       "2                                   Spice Elephant   \n",
       "3                                  San Churro Cafe   \n",
       "4                            Addhuri Udupi Bhojana   \n",
       "5                                    Grand Village   \n",
       "6                                    Casual Dining   \n",
       "7                                  Timepass Dinner   \n",
       "8                                    Casual Dining   \n",
       "9  Rosewood International Hotel - Bar & Restaurant   \n",
       "\n",
       "                                        online_order  \\\n",
       "0                                                Yes   \n",
       "1  Pasta, Lunch Buffet, Masala Papad, Paneer Laja...   \n",
       "2                                                Yes   \n",
       "3                                                Yes   \n",
       "4                                                 No   \n",
       "5                                                 No   \n",
       "6                                Panipuri, Gol Gappe   \n",
       "7                                                Yes   \n",
       "8  Onion Rings, Pasta, Kadhai Paneer, Salads, Sal...   \n",
       "9                                                 No   \n",
       "\n",
       "                       book_table   rate  \\\n",
       "0                             Yes  4.1/5   \n",
       "1  North Indian, Mughlai, Chinese    800   \n",
       "2                              No  4.1/5   \n",
       "3                              No  3.8/5   \n",
       "4                              No  3.7/5   \n",
       "5                              No  3.8/5   \n",
       "6        North Indian, Rajasthani    600   \n",
       "7                              No  3.8/5   \n",
       "8                    North Indian    600   \n",
       "9                              No  3.6/5   \n",
       "\n",
       "                                               votes           phone  \\\n",
       "0                                                775    080 42297555   \n",
       "1  \"[('Rated 4.0', 'RATED\\n  A beautiful place to...    ('Rated 4.0'   \n",
       "2                                                787    080 41714161   \n",
       "3                                                918  +91 9663487993   \n",
       "4                                                 88  +91 9620009302   \n",
       "5                                                166  +91 8026612447   \n",
       "6  [('Rated 4.0', 'RATED\\n  Very good restaurant ...              []   \n",
       "7                                                286  +91 9980040002   \n",
       "8  [('Rated 3.0', 'RATED\\n  Food 3/5\\nAmbience 3/...              []   \n",
       "9                                                  8  +91 9731716688   \n",
       "\n",
       "                                            location            rest_type  \\\n",
       "0                                               None                 None   \n",
       "1   'RATED\\n  You can\\x83\\x83\\x82\\x82\\x...         ('Rated 5.0'   \n",
       "2                                       Banashankari        Casual Dining   \n",
       "3                                       Banashankari  Cafe, Casual Dining   \n",
       "4                                       Banashankari          Quick Bites   \n",
       "5                                               None                 None   \n",
       "6                                             Buffet         Banashankari   \n",
       "7                                               None                 None   \n",
       "8                                             Buffet         Banashankari   \n",
       "9                                               None                 None   \n",
       "\n",
       "                                          dish_liked  \\\n",
       "0                                               None   \n",
       "1   'RATED\\n  Overdelighted by the service and fo...   \n",
       "2  Momos, Lunch Buffet, Chocolate Nirvana, Thai G...   \n",
       "3  Churros, Cannelloni, Minestrone Soup, Hot Choc...   \n",
       "4                                        Masala Dosa   \n",
       "5                                               None   \n",
       "6                                               None   \n",
       "7                                               None   \n",
       "8                                               None   \n",
       "9                                               None   \n",
       "\n",
       "                      cuisines  \\\n",
       "0                         None   \n",
       "1                 ('Rated 4.0'   \n",
       "2  Chinese, North Indian, Thai   \n",
       "3       Cafe, Mexican, Italian   \n",
       "4   South Indian, North Indian   \n",
       "5                         None   \n",
       "6                         None   \n",
       "7                         None   \n",
       "8                         None   \n",
       "9                         None   \n",
       "\n",
       "                         approx_cost(for two people)  \\\n",
       "0                                               None   \n",
       "1   'RATED\\n  The place is nice and comfortable. ...   \n",
       "2                                                800   \n",
       "3                                                800   \n",
       "4                                                300   \n",
       "5                                               None   \n",
       "6                                               None   \n",
       "7                                               None   \n",
       "8                                               None   \n",
       "9                                               None   \n",
       "\n",
       "                                        reviews_list  \\\n",
       "0                                               None   \n",
       "1                                       ('Rated 4.0'   \n",
       "2  \"[('Rated 4.0', 'RATED\\n  Had been here for di...   \n",
       "3  \"[('Rated 3.0', \"\"RATED\\n  Ambience is not tha...   \n",
       "4  \"[('Rated 4.0', \"\"RATED\\n  Great food and prop...   \n",
       "5                                               None   \n",
       "6                                               None   \n",
       "7                                               None   \n",
       "8                                               None   \n",
       "9                                               None   \n",
       "\n",
       "                                           menu_item  \\\n",
       "0                                               None   \n",
       "1   'RATED\\n  The place is nice and comfortable. ...   \n",
       "2  rice was well cooked and overall was great\\n\\n...   \n",
       "3                                       ('Rated 3.0'   \n",
       "4                                       ('Rated 2.0'   \n",
       "5                                               None   \n",
       "6                                               None   \n",
       "7                                               None   \n",
       "8                                               None   \n",
       "9                                               None   \n",
       "\n",
       "                                     listed_in(type)  \\\n",
       "0                                               None   \n",
       "1                                       ('Rated 4.0'   \n",
       "2                                       ('Rated 5.0'   \n",
       "3   \"\"RATED\\n \\nWent there for a quick bite with ...   \n",
       "4   'RATED\\n  Reached the place at 3pm on Saturda...   \n",
       "5                                               None   \n",
       "6                                               None   \n",
       "7                                               None   \n",
       "8                                               None   \n",
       "9                                               None   \n",
       "\n",
       "                                     listed_in(city)  \n",
       "0                                               None  \n",
       "1   'RATED\\n  The place is nice and comfortable. ...  \n",
       "2   'RATED\\n  This place just cool ? with good am...  \n",
       "3   pasta churros and lasagne.\\n\\nNachos were pat...  \n",
       "4                                       ('Rated 4.0'  \n",
       "5                                               None  \n",
       "6                                               None  \n",
       "7                                               None  \n",
       "8                                               None  \n",
       "9                                               None  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill all nulls values with one common value (numeric value)\n",
    "df.na.fill(999).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually you should specify what columns you want to fill with the subset parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>address</th>\n",
       "      <th>name</th>\n",
       "      <th>online_order</th>\n",
       "      <th>book_table</th>\n",
       "      <th>rate</th>\n",
       "      <th>votes</th>\n",
       "      <th>phone</th>\n",
       "      <th>location</th>\n",
       "      <th>rest_type</th>\n",
       "      <th>dish_liked</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>approx_cost(for two people)</th>\n",
       "      <th>reviews_list</th>\n",
       "      <th>menu_item</th>\n",
       "      <th>listed_in(type)</th>\n",
       "      <th>listed_in(city)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+91 9986692090\"</td>\n",
       "      <td>BTM</td>\n",
       "      <td>No Name</td>\n",
       "      <td>Momos, Oreo Shake</td>\n",
       "      <td>Mughlai, North Indian, Chinese, Momos</td>\n",
       "      <td>600</td>\n",
       "      <td>\"[('Rated 5.0', \"\"RATED\\n  Ordered Chicken Kad...</td>\n",
       "      <td>('Rated 3.0'</td>\n",
       "      <td>'RATED\\n  Simple food with great north indian...</td>\n",
       "      <td>['Fry Chicken Kabab [5 Pieces]', 'Fry Chicken ...</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>Bannerghatta Road</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00 805074123\"</td>\n",
       "      <td>BTM</td>\n",
       "      <td>No Name</td>\n",
       "      <td>None</td>\n",
       "      <td>North Indian, Chinese, Arabian</td>\n",
       "      <td>700</td>\n",
       "      <td>\"[('Rated 2.0', 'RATED\\n  You would only go to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>Bannerghatta Road</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+91 8971051846\"</td>\n",
       "      <td>Bannerghatta Road</td>\n",
       "      <td>No Name</td>\n",
       "      <td>None</td>\n",
       "      <td>Street Food, Burger</td>\n",
       "      <td>150</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>Bannerghatta Road</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>080 39457777\"</td>\n",
       "      <td>Bannerghatta Road</td>\n",
       "      <td>No Name</td>\n",
       "      <td>Chicken Biryani, Hyderabadi Biryani, Rolls, Mu...</td>\n",
       "      <td>Biryani, North Indian</td>\n",
       "      <td>500</td>\n",
       "      <td>\"[('Rated 3.0', 'RATED\\n  If you a spicy biriy...</td>\n",
       "      <td>('Rated 3.0'</td>\n",
       "      <td>'RATED\\n  too much oil in rice items')</td>\n",
       "      <td>('Rated 2.0'</td>\n",
       "      <td>'RATED\\n  salan was not provided')</td>\n",
       "      <td>('Rated 1.0'</td>\n",
       "      <td>'RATED\\n  I ordered aam ras n received nimbu ...</td>\n",
       "      <td>('Rated 3.0'</td>\n",
       "      <td>'RATED\\n  ok ok biryani')</td>\n",
       "      <td>('Rated 1.0'</td>\n",
       "      <td>\"\"RATED\\n  poor test &amp; quality... will never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+91 8971051846\"</td>\n",
       "      <td>Bannerghatta Road</td>\n",
       "      <td>No Name</td>\n",
       "      <td>None</td>\n",
       "      <td>Street Food, Burger</td>\n",
       "      <td>150</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Dine-out</td>\n",
       "      <td>Bannerghatta Road</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               url            address     name  \\\n",
       "0  +91 9986692090\"                BTM  No Name   \n",
       "1    00 805074123\"                BTM  No Name   \n",
       "2  +91 8971051846\"  Bannerghatta Road  No Name   \n",
       "3    080 39457777\"  Bannerghatta Road  No Name   \n",
       "4  +91 8971051846\"  Bannerghatta Road  No Name   \n",
       "\n",
       "                                        online_order  \\\n",
       "0                                  Momos, Oreo Shake   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  Chicken Biryani, Hyderabadi Biryani, Rolls, Mu...   \n",
       "4                                               None   \n",
       "\n",
       "                              book_table rate  \\\n",
       "0  Mughlai, North Indian, Chinese, Momos  600   \n",
       "1         North Indian, Chinese, Arabian  700   \n",
       "2                    Street Food, Burger  150   \n",
       "3                  Biryani, North Indian  500   \n",
       "4                    Street Food, Burger  150   \n",
       "\n",
       "                                               votes          phone  \\\n",
       "0  \"[('Rated 5.0', \"\"RATED\\n  Ordered Chicken Kad...   ('Rated 3.0'   \n",
       "1  \"[('Rated 2.0', 'RATED\\n  You would only go to...             []   \n",
       "2                                                 []             []   \n",
       "3  \"[('Rated 3.0', 'RATED\\n  If you a spicy biriy...   ('Rated 3.0'   \n",
       "4                                                 []             []   \n",
       "\n",
       "                                            location  \\\n",
       "0   'RATED\\n  Simple food with great north indian...   \n",
       "1                                           Delivery   \n",
       "2                                           Delivery   \n",
       "3             'RATED\\n  too much oil in rice items')   \n",
       "4                                           Dine-out   \n",
       "\n",
       "                                           rest_type  \\\n",
       "0  ['Fry Chicken Kabab [5 Pieces]', 'Fry Chicken ...   \n",
       "1                                  Bannerghatta Road   \n",
       "2                                  Bannerghatta Road   \n",
       "3                                       ('Rated 2.0'   \n",
       "4                                  Bannerghatta Road   \n",
       "\n",
       "                            dish_liked           cuisines  \\\n",
       "0                             Delivery  Bannerghatta Road   \n",
       "1                                 None               None   \n",
       "2                                 None               None   \n",
       "3   'RATED\\n  salan was not provided')       ('Rated 1.0'   \n",
       "4                                 None               None   \n",
       "\n",
       "                         approx_cost(for two people)   reviews_list  \\\n",
       "0                                               None           None   \n",
       "1                                               None           None   \n",
       "2                                               None           None   \n",
       "3   'RATED\\n  I ordered aam ras n received nimbu ...   ('Rated 3.0'   \n",
       "4                                               None           None   \n",
       "\n",
       "                    menu_item listed_in(type)  \\\n",
       "0                        None            None   \n",
       "1                        None            None   \n",
       "2                        None            None   \n",
       "3   'RATED\\n  ok ok biryani')    ('Rated 1.0'   \n",
       "4                        None            None   \n",
       "\n",
       "                                     listed_in(city)  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3   \"\"RATED\\n  poor test & quality... will never ...  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.name.isNull()).na.fill('No Name',subset=['name']).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very common practice is to fill values with the mean value for the column. Here is a fun function to that in an automatted way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>address</th>\n",
       "      <th>name</th>\n",
       "      <th>online_order</th>\n",
       "      <th>book_table</th>\n",
       "      <th>rate</th>\n",
       "      <th>votes</th>\n",
       "      <th>phone</th>\n",
       "      <th>location</th>\n",
       "      <th>rest_type</th>\n",
       "      <th>dish_liked</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>approx_cost(for two people)</th>\n",
       "      <th>reviews_list</th>\n",
       "      <th>menu_item</th>\n",
       "      <th>listed_in(type)</th>\n",
       "      <th>listed_in(city)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.zomato.com/bangalore/jalsa-banasha...</td>\n",
       "      <td>942, 21st Main Road, 2nd Stage, Banashankari, ...</td>\n",
       "      <td>Jalsa</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.1/5</td>\n",
       "      <td>775</td>\n",
       "      <td>080 42297555</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>387.40837156371134</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+91 9743772233\"</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Pasta, Lunch Buffet, Masala Papad, Paneer Laja...</td>\n",
       "      <td>North Indian, Mughlai, Chinese</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 4.0', 'RATED\\n  A beautiful place to...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  You can\\x83\\x83\\x82\\x82\\x...</td>\n",
       "      <td>('Rated 5.0'</td>\n",
       "      <td>'RATED\\n  Overdelighted by the service and fo...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "      <td>'RATED\\n  The place is nice and comfortable. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.zomato.com/bangalore/spice-elephan...</td>\n",
       "      <td>2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...</td>\n",
       "      <td>Spice Elephant</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.1/5</td>\n",
       "      <td>787</td>\n",
       "      <td>080 41714161</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Momos, Lunch Buffet, Chocolate Nirvana, Thai G...</td>\n",
       "      <td>Chinese, North Indian, Thai</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 4.0', 'RATED\\n  Had been here for di...</td>\n",
       "      <td>rice was well cooked and overall was great\\n\\n...</td>\n",
       "      <td>('Rated 5.0'</td>\n",
       "      <td>'RATED\\n  This place just cool ? with good am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zomato.com/SanchurroBangalore?cont...</td>\n",
       "      <td>1112, Next to KIMS Medical College, 17th Cross...</td>\n",
       "      <td>San Churro Cafe</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8/5</td>\n",
       "      <td>918</td>\n",
       "      <td>+91 9663487993</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Cafe, Casual Dining</td>\n",
       "      <td>Churros, Cannelloni, Minestrone Soup, Hot Choc...</td>\n",
       "      <td>Cafe, Mexican, Italian</td>\n",
       "      <td>800</td>\n",
       "      <td>\"[('Rated 3.0', \"\"RATED\\n  Ambience is not tha...</td>\n",
       "      <td>('Rated 3.0'</td>\n",
       "      <td>\"\"RATED\\n \\nWent there for a quick bite with ...</td>\n",
       "      <td>pasta churros and lasagne.\\n\\nNachos were pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.zomato.com/bangalore/addhuri-udupi...</td>\n",
       "      <td>1st Floor, Annakuteera, 3rd Stage, Banashankar...</td>\n",
       "      <td>Addhuri Udupi Bhojana</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.7/5</td>\n",
       "      <td>88</td>\n",
       "      <td>+91 9620009302</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Quick Bites</td>\n",
       "      <td>Masala Dosa</td>\n",
       "      <td>South Indian, North Indian</td>\n",
       "      <td>300</td>\n",
       "      <td>\"[('Rated 4.0', \"\"RATED\\n  Great food and prop...</td>\n",
       "      <td>('Rated 2.0'</td>\n",
       "      <td>'RATED\\n  Reached the place at 3pm on Saturda...</td>\n",
       "      <td>('Rated 4.0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.zomato.com/bangalore/jalsa-banasha...   \n",
       "1                                    +91 9743772233\"   \n",
       "2  https://www.zomato.com/bangalore/spice-elephan...   \n",
       "3  https://www.zomato.com/SanchurroBangalore?cont...   \n",
       "4  https://www.zomato.com/bangalore/addhuri-udupi...   \n",
       "\n",
       "                                             address                   name  \\\n",
       "0  942, 21st Main Road, 2nd Stage, Banashankari, ...                  Jalsa   \n",
       "1                                       Banashankari          Casual Dining   \n",
       "2  2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...         Spice Elephant   \n",
       "3  1112, Next to KIMS Medical College, 17th Cross...        San Churro Cafe   \n",
       "4  1st Floor, Annakuteera, 3rd Stage, Banashankar...  Addhuri Udupi Bhojana   \n",
       "\n",
       "                                        online_order  \\\n",
       "0                                                Yes   \n",
       "1  Pasta, Lunch Buffet, Masala Papad, Paneer Laja...   \n",
       "2                                                Yes   \n",
       "3                                                Yes   \n",
       "4                                                 No   \n",
       "\n",
       "                       book_table   rate  \\\n",
       "0                             Yes  4.1/5   \n",
       "1  North Indian, Mughlai, Chinese    800   \n",
       "2                              No  4.1/5   \n",
       "3                              No  3.8/5   \n",
       "4                              No  3.7/5   \n",
       "\n",
       "                                               votes           phone  \\\n",
       "0                                                775    080 42297555   \n",
       "1  \"[('Rated 4.0', 'RATED\\n  A beautiful place to...    ('Rated 4.0'   \n",
       "2                                                787    080 41714161   \n",
       "3                                                918  +91 9663487993   \n",
       "4                                                 88  +91 9620009302   \n",
       "\n",
       "                                            location            rest_type  \\\n",
       "0                                               None                 None   \n",
       "1   'RATED\\n  You can\\x83\\x83\\x82\\x82\\x...         ('Rated 5.0'   \n",
       "2                                       Banashankari        Casual Dining   \n",
       "3                                       Banashankari  Cafe, Casual Dining   \n",
       "4                                       Banashankari          Quick Bites   \n",
       "\n",
       "                                          dish_liked  \\\n",
       "0                                               None   \n",
       "1   'RATED\\n  Overdelighted by the service and fo...   \n",
       "2  Momos, Lunch Buffet, Chocolate Nirvana, Thai G...   \n",
       "3  Churros, Cannelloni, Minestrone Soup, Hot Choc...   \n",
       "4                                        Masala Dosa   \n",
       "\n",
       "                      cuisines  \\\n",
       "0                         None   \n",
       "1                 ('Rated 4.0'   \n",
       "2  Chinese, North Indian, Thai   \n",
       "3       Cafe, Mexican, Italian   \n",
       "4   South Indian, North Indian   \n",
       "\n",
       "                         approx_cost(for two people)  \\\n",
       "0                                 387.40837156371134   \n",
       "1   'RATED\\n  The place is nice and comfortable. ...   \n",
       "2                                                800   \n",
       "3                                                800   \n",
       "4                                                300   \n",
       "\n",
       "                                        reviews_list  \\\n",
       "0                                               None   \n",
       "1                                       ('Rated 4.0'   \n",
       "2  \"[('Rated 4.0', 'RATED\\n  Had been here for di...   \n",
       "3  \"[('Rated 3.0', \"\"RATED\\n  Ambience is not tha...   \n",
       "4  \"[('Rated 4.0', \"\"RATED\\n  Great food and prop...   \n",
       "\n",
       "                                           menu_item  \\\n",
       "0                                               None   \n",
       "1   'RATED\\n  The place is nice and comfortable. ...   \n",
       "2  rice was well cooked and overall was great\\n\\n...   \n",
       "3                                       ('Rated 3.0'   \n",
       "4                                       ('Rated 2.0'   \n",
       "\n",
       "                                     listed_in(type)  \\\n",
       "0                                               None   \n",
       "1                                       ('Rated 4.0'   \n",
       "2                                       ('Rated 5.0'   \n",
       "3   \"\"RATED\\n \\nWent there for a quick bite with ...   \n",
       "4   'RATED\\n  Reached the place at 3pm on Saturda...   \n",
       "\n",
       "                                     listed_in(city)  \n",
       "0                                               None  \n",
       "1   'RATED\\n  The place is nice and comfortable. ...  \n",
       "2   'RATED\\n  This place just cool ? with good am...  \n",
       "3   pasta churros and lasagne.\\n\\nNachos were pat...  \n",
       "4                                       ('Rated 4.0'  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fill_with_mean(df, include=set()): \n",
    "    stats = df.agg(*(\n",
    "        avg(c).alias(c) for c in df.columns if c in include\n",
    "    ))\n",
    "#     stats = stats.select(*(col(c).cast(\"int\").alias(c) for c in stats.columns)) #IntegerType()\n",
    "    return df.na.fill(stats.first().asDict())\n",
    "\n",
    "updated_df = fill_with_mean(df, [\"approx_cost(for two people)\",\"votes\"])\n",
    "updated_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Data in DataFrames\n",
    "\n",
    "Change data types\n",
    "\n",
    "### Available types:\n",
    "    - DataType\n",
    "    - NullType\n",
    "    - StringType\n",
    "    - BinaryType\n",
    "    - BooleanType\n",
    "    - DateType\n",
    "    - TimestampType\n",
    "    - DecimalType\n",
    "    - DoubleType\n",
    "    - FloatType\n",
    "    - ByteType\n",
    "    - IntegerType\n",
    "    - LongType\n",
    "    - ShortType\n",
    "    - ArrayType\n",
    "    - MapType\n",
    "    - StructField\n",
    "    - StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- trending_date: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- category_id: string (nullable = true)\n",
      " |-- publish_time: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- views: string (nullable = true)\n",
      " |-- likes: string (nullable = true)\n",
      " |-- dislikes: string (nullable = true)\n",
      " |-- comment_count: string (nullable = true)\n",
      " |-- thumbnail_link: string (nullable = true)\n",
      " |-- comments_disabled: string (nullable = true)\n",
      " |-- ratings_disabled: string (nullable = true)\n",
      " |-- video_error_or_removed: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>\"last week tonight trump presidency\"|\"last wee...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>\"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO  \\n\\nSUBSCRIBE  http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puqaWrEC7tY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>\"rhett and link\"|\"gmm\"|\"good mythical morning\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  2kyS6SvSYSE      17.14.11   \n",
       "1  1ZAPwfrtAFY      17.14.11   \n",
       "2  5qpjK5DgCt4      17.14.11   \n",
       "3  puqaWrEC7tY      17.14.11   \n",
       "\n",
       "                                               title          channel_title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
       "\n",
       "  category_id              publish_time  \\\n",
       "0          22  2017-11-13T17:13:01.000Z   \n",
       "1          24  2017-11-13T07:30:00.000Z   \n",
       "2          23  2017-11-12T19:05:24.000Z   \n",
       "3          24  2017-11-13T11:00:04.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  \"last week tonight trump presidency\"|\"last wee...  2418783   97185   \n",
       "2  \"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...  3191434  146033   \n",
       "3  \"rhett and link\"|\"gmm\"|\"good mythical morning\"...   343168   10172   \n",
       "\n",
       "  dislikes comment_count                                  thumbnail_link  \\\n",
       "0     2966         15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1     6146         12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2     5339          8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3      666          2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "\n",
       "  comments_disabled ratings_disabled video_error_or_removed  \\\n",
       "0             False            False                  False   \n",
       "1             False            False                  False   \n",
       "2             False            False                  False   \n",
       "3             False            False                  False   \n",
       "\n",
       "                                         description  \n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
       "1  One year after the presidential election, John...  \n",
       "2  WATCH MY PREVIOUS VIDEO  \\n\\nSUBSCRIBE  http...  \n",
       "3  Today we find out if Link is a Nickelback amat...  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "df = spark.read.csv(path+'youtubevideos.csv', inferSchema=True,header=True)\n",
    "print(df.printSchema())\n",
    "df.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex**\n",
    "\n",
    "Regex is used to replace or extract all substrings of the specified string value that match regexp with rep.\n",
    "regexp_replace(str, pattern, replacement)\n",
    "for more info on regex calls visit: https://docs.oracle.com/cd/B19306_01/server.102/b14200/ap_posix001.htm#BABJDBHB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- trending_date: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- category_id: string (nullable = true)\n",
      " |-- publish_time: timestamp (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- views: string (nullable = true)\n",
      " |-- likes: string (nullable = true)\n",
      " |-- dislikes: string (nullable = true)\n",
      " |-- comment_count: string (nullable = true)\n",
      " |-- thumbnail_link: string (nullable = true)\n",
      " |-- comments_disabled: string (nullable = true)\n",
      " |-- ratings_disabled: string (nullable = true)\n",
      " |-- video_error_or_removed: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13 17:13:01</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13 07:30:00</td>\n",
       "      <td>\"last week tonight trump presidency\"|\"last wee...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12 19:05:24</td>\n",
       "      <td>\"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO  \\n\\nSUBSCRIBE  http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puqaWrEC7tY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13 11:00:04</td>\n",
       "      <td>\"rhett and link\"|\"gmm\"|\"good mythical morning\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  2kyS6SvSYSE      17.14.11   \n",
       "1  1ZAPwfrtAFY      17.14.11   \n",
       "2  5qpjK5DgCt4      17.14.11   \n",
       "3  puqaWrEC7tY      17.14.11   \n",
       "\n",
       "                                               title          channel_title  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
       "\n",
       "  category_id        publish_time  \\\n",
       "0          22 2017-11-13 17:13:01   \n",
       "1          24 2017-11-13 07:30:00   \n",
       "2          23 2017-11-12 19:05:24   \n",
       "3          24 2017-11-13 11:00:04   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  \"last week tonight trump presidency\"|\"last wee...  2418783   97185   \n",
       "2  \"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...  3191434  146033   \n",
       "3  \"rhett and link\"|\"gmm\"|\"good mythical morning\"...   343168   10172   \n",
       "\n",
       "  dislikes comment_count                                  thumbnail_link  \\\n",
       "0     2966         15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1     6146         12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2     5339          8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3      666          2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "\n",
       "  comments_disabled ratings_disabled video_error_or_removed  \\\n",
       "0             False            False                  False   \n",
       "1             False            False                  False   \n",
       "2             False            False                  False   \n",
       "3             False            False                  False   \n",
       "\n",
       "                                         description  \n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
       "1  One year after the presidential election, John...  \n",
       "2  WATCH MY PREVIOUS VIDEO  \\n\\nSUBSCRIBE  http...  \n",
       "3  Today we find out if Link is a Nickelback amat...  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace, regexp_extract\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "df = df.withColumn('publish_time',regexp_replace(df.publish_time, 'T', ' '))\n",
    "df = df.withColumn('publish_time',regexp_replace(df.publish_time, 'Z', ''))\n",
    "df = df.withColumn(\"publish_time\", to_timestamp(df.publish_time, 'yyyy-MM-dd HH:mm:ss.SSS'))\n",
    "print(df.printSchema())\n",
    "df.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Translate Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|                 A|          replaced|\n",
      "+------------------+------------------+\n",
      "|           $100,00|           X100Z00|\n",
      "|           #foobar|           Yfoobar|\n",
      "|foo, bar, #, and $|fooZ barZ YZ and X|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also use the translate function for cases like this \n",
    "# where you wanted to replace ('$', '#', ',') with ('X', 'Y', 'Z')\n",
    "import pyspark.sql.functions as f\n",
    "foobar = spark.createDataFrame([(\"$100,00\",),(\"#foobar\",),(\"foo, bar, #, and $\",)], [\"A\"])\n",
    "foobar.select(\"A\", f.translate(f.col(\"A\"), \"$#,\", \"XYZ\").alias(\"replaced\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trim**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|          d1|          d2|\n",
      "+------------+------------+\n",
      "| 2015-04-08 | 2015-05-10 |\n",
      "+------------+------------+\n",
      "\n",
      "left trim\n",
      "+------------+-----------+\n",
      "|          d1|  ltrim(d1)|\n",
      "+------------+-----------+\n",
      "| 2015-04-08 |2015-04-08 |\n",
      "+------------+-----------+\n",
      "\n",
      "right trim\n",
      "+------------+-----------+\n",
      "|          d1|  rtrim(d1)|\n",
      "+------------+-----------+\n",
      "| 2015-04-08 | 2015-04-08|\n",
      "+------------+-----------+\n",
      "\n",
      "trim\n",
      "+------------+----------+\n",
      "|          d1|  trim(d1)|\n",
      "+------------+----------+\n",
      "| 2015-04-08 |2015-04-08|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trim\n",
    "# pyspark.sql.functions.trim(col) - Trim the spaces from both ends for the specified string column.\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "trim_ex = spark.createDataFrame([(' 2015-04-08 ',' 2015-05-10 ')], ['d1', 'd2']) # create a dataframe - notice the extra whitespaces in the date strings\n",
    "trim_ex.show()\n",
    "print(\"left trim\")\n",
    "trim_ex.select('d1', ltrim(trim_ex.d1)).show()\n",
    "print(\"right trim\")\n",
    "trim_ex.select('d1', rtrim(trim_ex.d1)).show()\n",
    "print(\"trim\")\n",
    "trim_ex.select('d1', trim(trim_ex.d1)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case When**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Dataframe:\n",
      "+---+-----+\n",
      "| id|value|\n",
      "+---+-----+\n",
      "|  1|    1|\n",
      "|  2|    2|\n",
      "|  3|    3|\n",
      "+---+-----+\n",
      "\n",
      "Option#1: withColumn() using when-otherwise\n",
      "+---+-----+----------+\n",
      "| id|value|value_desc|\n",
      "+---+-----+----------+\n",
      "|  1|    1|       one|\n",
      "|  2|    2|       two|\n",
      "|  3|    3|     other|\n",
      "+---+-----+----------+\n",
      "\n",
      "Option2: withColumn() using expr function\n",
      "+---+-----+----------+\n",
      "| id|value|value_desc|\n",
      "+---+-----+----------+\n",
      "|  1|    1|       one|\n",
      "|  2|    2|       two|\n",
      "|  3|    3|     other|\n",
      "+---+-----+----------+\n",
      "\n",
      "Option 3: selectExpr() using SQL equivalent CASE expression\n",
      "+---+------+-----------------+---+--------------------+-----------+--------------------+-------+---------+-------------------+--------------------+-------+-----+-------+--------------+------------------------+---------+-----------+--------------+----------+---------+--------+-------------+------------+-----------+--------------------+------+------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+--------+---------+---------------+------------+-------+---------+-----+----------+-----------+-----------+------------+-----------+-------+---------+-------+---------+-------+-------+--------+---------+----------+-------------+-----------+------+---------+---------+-------+--------------+-------------+--------+----------+---------+-------------+----------+--------------+----------+\n",
      "|_c0|    ID|             Name|Age|               Photo|Nationality|                Flag|Overall|Potential|               Club|           Club Logo|  Value| Wage|Special|Preferred Foot|International Reputation|Weak Foot|Skill Moves|     Work Rate| Body Type|Real Face|Position|Jersey Number|      Joined|Loaned From|Contract Valid Until|Height|Weight|  LS|  ST|  RS|  LW|  LF|  CF|  RF|  RW| LAM| CAM| RAM|  LM| LCM|  CM| RCM|  RM| LWB| LDM| CDM| RDM| RWB|  LB| LCB|  CB| RCB|  RB|Crossing|Finishing|HeadingAccuracy|ShortPassing|Volleys|Dribbling|Curve|FKAccuracy|LongPassing|BallControl|Acceleration|SprintSpeed|Agility|Reactions|Balance|ShotPower|Jumping|Stamina|Strength|LongShots|Aggression|Interceptions|Positioning|Vision|Penalties|Composure|Marking|StandingTackle|SlidingTackle|GKDiving|GKHandling|GKKicking|GKPositioning|GKReflexes|Release Clause|value_desc|\n",
      "+---+------+-----------------+---+--------------------+-----------+--------------------+-------+---------+-------------------+--------------------+-------+-----+-------+--------------+------------------------+---------+-----------+--------------+----------+---------+--------+-------------+------------+-----------+--------------------+------+------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+--------+---------+---------------+------------+-------+---------+-----+----------+-----------+-----------+------------+-----------+-------+---------+-------+---------+-------+-------+--------+---------+----------+-------------+-----------+------+---------+---------+-------+--------------+-------------+--------+----------+---------+-------------+----------+--------------+----------+\n",
      "|  0|158023|         L. Messi| 31|https://cdn.sofif...|  Argentina|https://cdn.sofif...|     94|       94|       FC Barcelona|https://cdn.sofif...|110.5M|565K|   2202|          Left|                       5|        4|          4|Medium/ Medium|     Messi|      Yes|      RF|           10| Jul 1, 2004|       null|                2021|   5'7|159lbs|88+2|88+2|88+2|92+2|93+2|93+2|93+2|92+2|93+2|93+2|93+2|91+2|84+2|84+2|84+2|91+2|64+2|61+2|61+2|61+2|64+2|59+2|47+2|47+2|47+2|59+2|      84|       95|             70|          90|     86|       97|   93|        94|         87|         96|          91|         86|     91|       95|     95|       85|     68|     72|      59|       94|        48|           22|         94|    94|       75|       96|     33|            28|           26|       6|        11|       15|           14|         8|       226.5M|     other|\n",
      "|  1| 20801|Cristiano Ronaldo| 33|https://cdn.sofif...|   Portugal|https://cdn.sofif...|     94|       94|           Juventus|https://cdn.sofif...|   77M|405K|   2228|         Right|                       5|        4|          5|     High/ Low|C. Ronaldo|      Yes|      ST|            7|Jul 10, 2018|       null|                2022|   6'2|183lbs|91+3|91+3|91+3|89+3|90+3|90+3|90+3|89+3|88+3|88+3|88+3|88+3|81+3|81+3|81+3|88+3|65+3|61+3|61+3|61+3|65+3|61+3|53+3|53+3|53+3|61+3|      84|       94|             89|          81|     87|       88|   81|        76|         77|         94|          89|         91|     87|       96|     70|       95|     95|     88|      79|       93|        63|           29|         95|    82|       85|       95|     28|            31|           23|       7|        11|       15|           14|        11|       127.1M|     other|\n",
      "|  2|190871|        Neymar Jr| 26|https://cdn.sofif...|     Brazil|https://cdn.sofif...|     92|       93|Paris Saint-Germain|https://cdn.sofif...|118.5M|290K|   2143|         Right|                       5|        5|          5|  High/ Medium|    Neymar|      Yes|      LW|           10| Aug 3, 2017|       null|                2022|   5'9|150lbs|84+3|84+3|84+3|89+3|89+3|89+3|89+3|89+3|89+3|89+3|89+3|88+3|81+3|81+3|81+3|88+3|65+3|60+3|60+3|60+3|65+3|60+3|47+3|47+3|47+3|60+3|      79|       87|             62|          84|     84|       96|   88|        87|         78|         95|          94|         90|     96|       94|     84|       80|     61|     81|      49|       82|        56|           36|         89|    87|       81|       94|     27|            24|           33|       9|         9|       15|           15|        11|       228.1M|     other|\n",
      "|  3|193080|           De Gea| 27|https://cdn.sofif...|      Spain|https://cdn.sofif...|     91|       93|  Manchester United|https://cdn.sofif...|   72M|260K|   1471|         Right|                       4|        3|          1|Medium/ Medium|      Lean|      Yes|      GK|            1| Jul 1, 2011|       null|                2020|   6'4|168lbs|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|      17|       13|             21|          50|     13|       18|   21|        19|         51|         42|          57|         58|     60|       90|     43|       31|     67|     43|      64|       12|        38|           30|         12|    68|       40|       68|     15|            21|           13|      90|        85|       87|           88|        94|       138.6M|     other|\n",
      "|  4|192985|     K. De Bruyne| 27|https://cdn.sofif...|    Belgium|https://cdn.sofif...|     91|       92|    Manchester City|https://cdn.sofif...|  102M|355K|   2281|         Right|                       4|        5|          4|    High/ High|    Normal|      Yes|     RCM|            7|Aug 30, 2015|       null|                2023|  5'11|154lbs|82+3|82+3|82+3|87+3|87+3|87+3|87+3|87+3|88+3|88+3|88+3|88+3|87+3|87+3|87+3|88+3|77+3|77+3|77+3|77+3|77+3|73+3|66+3|66+3|66+3|73+3|      93|       82|             55|          92|     82|       86|   85|        83|         91|         91|          78|         76|     79|       91|     77|       91|     63|     90|      75|       91|        76|           61|         87|    94|       79|       88|     68|            58|           51|      15|        13|        5|           10|        13|       196.4M|     other|\n",
      "|  5|183277|        E. Hazard| 27|https://cdn.sofif...|    Belgium|https://cdn.sofif...|     91|       91|            Chelsea|https://cdn.sofif...|   93M|340K|   2142|         Right|                       4|        4|          4|  High/ Medium|    Normal|      Yes|      LF|           10| Jul 1, 2012|       null|                2020|   5'8|163lbs|83+3|83+3|83+3|89+3|88+3|88+3|88+3|89+3|89+3|89+3|89+3|89+3|82+3|82+3|82+3|89+3|66+3|63+3|63+3|63+3|66+3|60+3|49+3|49+3|49+3|60+3|      81|       84|             61|          89|     80|       95|   83|        79|         83|         94|          94|         88|     95|       90|     94|       82|     56|     83|      66|       80|        54|           41|         87|    89|       86|       91|     34|            27|           22|      11|        12|        6|            8|         8|       172.1M|     other|\n",
      "|  6|177003|        L. Modri| 32|https://cdn.sofif...|    Croatia|https://cdn.sofif...|     91|       91|        Real Madrid|https://cdn.sofif...|   67M|420K|   2280|         Right|                       4|        4|          4|    High/ High|      Lean|      Yes|     RCM|           10| Aug 1, 2012|       null|                2020|   5'8|146lbs|77+3|77+3|77+3|85+3|84+3|84+3|84+3|85+3|87+3|87+3|87+3|86+3|88+3|88+3|88+3|86+3|82+3|81+3|81+3|81+3|82+3|79+3|71+3|71+3|71+3|79+3|      86|       72|             55|          93|     76|       90|   85|        78|         88|         93|          80|         72|     93|       90|     94|       79|     68|     89|      58|       82|        62|           83|         79|    92|       82|       84|     60|            76|           73|      13|         9|        7|           14|         9|       137.4M|     other|\n",
      "|  7|176580|        L. Surez| 31|https://cdn.sofif...|    Uruguay|https://cdn.sofif...|     91|       91|       FC Barcelona|https://cdn.sofif...|   80M|455K|   2346|         Right|                       5|        4|          3|  High/ Medium|    Normal|      Yes|      RS|            9|Jul 11, 2014|       null|                2021|   6'0|190lbs|87+5|87+5|87+5|86+5|87+5|87+5|87+5|86+5|85+5|85+5|85+5|84+5|79+5|79+5|79+5|84+5|69+5|68+5|68+5|68+5|69+5|66+5|63+5|63+5|63+5|66+5|      77|       93|             77|          82|     88|       87|   86|        84|         64|         90|          86|         75|     82|       92|     83|       86|     69|     90|      83|       85|        87|           41|         92|    84|       85|       85|     62|            45|           38|      27|        25|       31|           33|        37|         164M|     other|\n",
      "|  8|155862|     Sergio Ramos| 32|https://cdn.sofif...|      Spain|https://cdn.sofif...|     91|       91|        Real Madrid|https://cdn.sofif...|   51M|380K|   2201|         Right|                       4|        3|          3|  High/ Medium|    Normal|      Yes|     RCB|           15| Aug 1, 2005|       null|                2020|   6'0|181lbs|73+3|73+3|73+3|70+3|71+3|71+3|71+3|70+3|71+3|71+3|71+3|72+3|75+3|75+3|75+3|72+3|81+3|84+3|84+3|84+3|81+3|84+3|87+3|87+3|87+3|84+3|      66|       60|             91|          78|     66|       63|   74|        72|         77|         84|          76|         75|     78|       85|     66|       79|     93|     84|      83|       59|        88|           90|         60|    63|       75|       82|     87|            92|           91|      11|         8|        9|            7|        11|       104.6M|     other|\n",
      "|  9|200389|         J. Oblak| 25|https://cdn.sofif...|   Slovenia|https://cdn.sofif...|     90|       93|    Atltico Madrid|https://cdn.sofif...|   68M| 94K|   1331|         Right|                       3|        3|          1|Medium/ Medium|    Normal|      Yes|      GK|            1|Jul 16, 2014|       null|                2021|   6'2|192lbs|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|      13|       11|             15|          29|     13|       12|   13|        14|         26|         16|          43|         60|     67|       86|     49|       22|     76|     41|      78|       12|        34|           19|         11|    70|       11|       70|     27|            12|           18|      86|        92|       78|           88|        89|       144.5M|     other|\n",
      "| 10|188545|   R. Lewandowski| 29|https://cdn.sofif...|     Poland|https://cdn.sofif...|     90|       90|  FC Bayern Mnchen|https://cdn.sofif...|   77M|205K|   2152|         Right|                       4|        4|          4|  High/ Medium|    Normal|      Yes|      ST|            9| Jul 1, 2014|       null|                2021|   6'0|176lbs|87+3|87+3|87+3|83+3|86+3|86+3|86+3|83+3|83+3|83+3|83+3|81+3|77+3|77+3|77+3|81+3|61+3|62+3|62+3|62+3|61+3|58+3|57+3|57+3|57+3|58+3|      62|       91|             85|          83|     89|       85|   77|        86|         65|         89|          77|         78|     78|       90|     78|       88|     84|     78|      84|       84|        80|           39|         91|    77|       88|       86|     34|            42|           19|      15|         6|       12|            8|        10|       127.1M|     other|\n",
      "| 11|182521|         T. Kroos| 28|https://cdn.sofif...|    Germany|https://cdn.sofif...|     90|       90|        Real Madrid|https://cdn.sofif...| 76.5M|355K|   2190|         Right|                       4|        5|          3|Medium/ Medium|    Normal|      Yes|     LCM|            8|Jul 17, 2014|       null|                2022|   6'0|168lbs|78+3|78+3|78+3|81+3|82+3|82+3|82+3|81+3|84+3|84+3|84+3|82+3|86+3|86+3|86+3|82+3|79+3|82+3|82+3|82+3|79+3|77+3|72+3|72+3|72+3|77+3|      88|       76|             54|          92|     82|       81|   86|        84|         93|         90|          64|         62|     70|       89|     71|       87|     30|     75|      73|       92|        60|           82|         79|    86|       73|       85|     72|            79|           69|      10|        11|       13|            7|        10|       156.8M|     other|\n",
      "| 12|182493|         D. Godn| 32|https://cdn.sofif...|    Uruguay|https://cdn.sofif...|     90|       90|    Atltico Madrid|https://cdn.sofif...|   44M|125K|   1946|         Right|                       3|        3|          2|  Medium/ High|      Lean|      Yes|      CB|           10| Aug 4, 2010|       null|                2019|   6'2|172lbs|64+3|64+3|64+3|61+3|62+3|62+3|62+3|61+3|62+3|62+3|62+3|63+3|68+3|68+3|68+3|63+3|76+3|81+3|81+3|81+3|76+3|79+3|87+3|87+3|87+3|79+3|      55|       42|             92|          79|     47|       53|   49|        51|         70|         76|          68|         68|     58|       85|     54|       67|     91|     66|      88|       43|        89|           88|         48|    52|       50|       82|     90|            89|           89|       6|         8|       15|            5|        15|        90.2M|     other|\n",
      "| 13|168542|      David Silva| 32|https://cdn.sofif...|      Spain|https://cdn.sofif...|     90|       90|    Manchester City|https://cdn.sofif...|   60M|285K|   2115|          Left|                       4|        2|          4|  High/ Medium|    Normal|      Yes|     LCM|           21|Jul 14, 2010|       null|                2020|   5'8|148lbs|77+3|77+3|77+3|85+3|84+3|84+3|84+3|85+3|87+3|87+3|87+3|85+3|85+3|85+3|85+3|85+3|69+3|70+3|70+3|70+3|69+3|64+3|57+3|57+3|57+3|64+3|      84|       76|             54|          93|     82|       89|   82|        77|         87|         94|          70|         64|     92|       90|     90|       72|     64|     78|      52|       75|        57|           50|         89|    92|       75|       93|     59|            53|           29|       6|        15|        7|            6|        12|         111M|     other|\n",
      "| 14|215914|         N. Kant| 27|https://cdn.sofif...|     France|https://cdn.sofif...|     89|       90|            Chelsea|https://cdn.sofif...|   63M|225K|   2189|         Right|                       3|        3|          2|  Medium/ High|      Lean|      Yes|     LDM|           13|Jul 16, 2016|       null|                2023|   5'6|159lbs|72+3|72+3|72+3|77+3|77+3|77+3|77+3|77+3|79+3|79+3|79+3|79+3|82+3|82+3|82+3|79+3|85+3|87+3|87+3|87+3|85+3|84+3|83+3|83+3|83+3|84+3|      68|       65|             54|          86|     56|       79|   49|        49|         81|         80|          82|         78|     82|       93|     92|       71|     77|     96|      76|       69|        90|           92|         71|    79|       54|       85|     90|            91|           85|      15|        12|       10|            7|        10|       121.3M|     other|\n",
      "| 15|211110|        P. Dybala| 24|https://cdn.sofif...|  Argentina|https://cdn.sofif...|     89|       94|           Juventus|https://cdn.sofif...|   89M|205K|   2092|          Left|                       3|        3|          4|  High/ Medium|    Normal|      Yes|      LF|           21| Jul 1, 2015|       null|                2022|  5'10|165lbs|83+3|83+3|83+3|87+3|86+3|86+3|86+3|87+3|87+3|87+3|87+3|86+3|79+3|79+3|79+3|86+3|62+3|58+3|58+3|58+3|62+3|56+3|45+3|45+3|45+3|56+3|      82|       84|             68|          87|     88|       92|   88|        88|         75|         92|          87|         83|     91|       86|     85|       82|     75|     80|      65|       88|        48|           32|         84|    87|       86|       84|     23|            20|           20|       5|         4|        4|            5|         8|       153.5M|     other|\n",
      "| 16|202126|          H. Kane| 24|https://cdn.sofif...|    England|https://cdn.sofif...|     89|       91|  Tottenham Hotspur|https://cdn.sofif...| 83.5M|205K|   2165|         Right|                       3|        4|          3|    High/ High|    Normal|      Yes|      ST|            9| Jul 1, 2010|       null|                2024|   6'2|196lbs|86+3|86+3|86+3|82+3|84+3|84+3|84+3|82+3|82+3|82+3|82+3|81+3|79+3|79+3|79+3|81+3|65+3|66+3|66+3|66+3|65+3|62+3|60+3|60+3|60+3|62+3|      75|       94|             85|          80|     84|       80|   78|        68|         82|         84|          68|         72|     71|       91|     71|       88|     78|     89|      84|       85|        76|           35|         93|    80|       90|       89|     56|            36|           38|       8|        10|       11|           14|        11|       160.7M|     other|\n",
      "| 17|194765|     A. Griezmann| 27|https://cdn.sofif...|     France|https://cdn.sofif...|     89|       90|    Atltico Madrid|https://cdn.sofif...|   78M|145K|   2246|          Left|                       4|        3|          4|    High/ High|      Lean|      Yes|     CAM|            7|Jul 28, 2014|       null|                2023|   5'9|161lbs|86+3|86+3|86+3|87+3|87+3|87+3|87+3|87+3|86+3|86+3|86+3|86+3|80+3|80+3|80+3|86+3|70+3|67+3|67+3|67+3|70+3|67+3|61+3|61+3|61+3|67+3|      82|       90|             84|          83|     87|       88|   84|        78|         76|         90|          88|         85|     90|       90|     80|       80|     90|     83|      62|       82|        69|           35|         91|    83|       79|       87|     59|            47|           48|      14|         8|       14|           13|        14|       165.8M|     other|\n",
      "| 18|192448|    M. ter Stegen| 26|https://cdn.sofif...|    Germany|https://cdn.sofif...|     89|       92|       FC Barcelona|https://cdn.sofif...|   58M|240K|   1328|         Right|                       3|        4|          1|Medium/ Medium|    Normal|      Yes|      GK|           22| Jul 1, 2014|       null|                2022|   6'2|187lbs|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|      15|       14|             11|          36|     14|       17|   18|        12|         42|         18|          38|         50|     37|       85|     43|       22|     79|     35|      79|       10|        43|           22|         11|    69|       25|       69|     25|            13|           10|      87|        85|       88|           85|        90|       123.3M|     other|\n",
      "| 19|192119|      T. Courtois| 26|https://cdn.sofif...|    Belgium|https://cdn.sofif...|     89|       90|        Real Madrid|https://cdn.sofif...| 53.5M|240K|   1311|          Left|                       4|        2|          1|Medium/ Medium|  Courtois|      Yes|      GK|            1| Aug 9, 2018|       null|                2024|   6'6|212lbs|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|      14|       14|             13|          33|     12|       13|   19|        20|         35|         23|          46|         52|     61|       84|     45|       36|     68|     38|      70|       17|        23|           15|         13|    44|       27|       66|     20|            18|           16|      85|        91|       72|           86|        88|       113.7M|     other|\n",
      "+---+------+-----------------+---+--------------------+-----------+--------------------+-------+---------+-------------------+--------------------+-------+-----+-------+--------------+------------------------+---------+-----------+--------------+----------+---------+--------+-------------+------------+-----------+--------------------+------+------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+--------+---------+---------------+------------+-------+---------+-----+----------+-----------+-----------+------------+-----------+-------+---------+-------+---------+-------+-------+--------+---------+----------+-------------+-----------+------+---------+---------+-------+--------------+-------------+--------+----------+---------+-------------+----------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Option 4: select() using expr function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| id|value|value_desc|\n",
      "+---+-----+----------+\n",
      "|  1|    1|       one|\n",
      "|  2|    2|       two|\n",
      "|  3|    3|     other|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(1,1),(2,2),(3,3)],['id','value'])\n",
    "\n",
    "print(\"Sample Dataframe:\")\n",
    "df.show()\n",
    "\n",
    "print(\"Option#1: withColumn() using when-otherwise\")\n",
    "from pyspark.sql.functions import when\n",
    "df.withColumn(\"value_desc\",when(df.value == 1, 'one').when(df.value == 2, 'two').otherwise('other')).show()\n",
    "\n",
    "print(\"Option2: withColumn() using expr function\")\n",
    "from pyspark.sql.functions import expr \n",
    "df.withColumn(\"value_desc\",expr(\"CASE WHEN value == 1 THEN  'one' WHEN value == 2 THEN  'two' ELSE 'other' END AS value_desc\")).show()\n",
    "\n",
    "print(\"Option 3: selectExpr() using SQL equivalent CASE expression\")\n",
    "fifa.selectExpr(\"*\",\"CASE WHEN value == 1 THEN  'one' WHEN value == 2 THEN  'two' ELSE 'other' END AS value_desc\").show()\n",
    "\n",
    "print(\"Option 4: select() using expr function\")\n",
    "from pyspark.sql.functions import expr \n",
    "df.select(\"*\",expr(\"CASE WHEN value == 1 THEN  'one' WHEN value == 2 THEN  'two' ELSE 'other' END AS value_desc\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|value|\n",
      "+---+-----+\n",
      "|  1|    1|\n",
      "|  2|    2|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use in between to filter values\n",
    "df = spark.createDataFrame([(1,1),(2,2),(3,3)],['id','value'])\n",
    "df.filter(df.value.between(1,2)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating new columns calculated using existing columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|  views|views_x_2|\n",
      "+-------+---------+\n",
      "| 748374|1496748.0|\n",
      "|2418783|4837566.0|\n",
      "|3191434|6382868.0|\n",
      "| 343168| 686336.0|\n",
      "+-------+---------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a new column from an existing column like this....\n",
    "# withColumn(colName, col)[source]\n",
    "# Returns a new DataFrame by adding a column or replacing the existing column that has the same name.\n",
    "# The column expression must be an expression over this DataFrame; attempting to add a column from some other dataframe will raise an error.\n",
    "\n",
    "# Parameters\n",
    "# colName  string, name of the new column.\n",
    "\n",
    "# col  a Column expression for the new column.\n",
    "df = spark.read.csv(path+'youtubevideos.csv', inferSchema=True,header=True)\n",
    "views = df.withColumn('views_x_2', df.views * 2)\n",
    "views.select(['views','views_x_2']).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|    views|views_x_2|\n",
      "+---------+---------+\n",
      "|1496748.0|1496748.0|\n",
      "|4837566.0|4837566.0|\n",
      "|6382868.0|6382868.0|\n",
      "| 686336.0| 686336.0|\n",
      "+---------+---------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also use this method to overwrite a column\n",
    "views = views.withColumn('views', views.views * 2)\n",
    "views.select(['views','views_x_2']).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title_new</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2kyS6SvSYSE</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
       "      <td>CaseyNeistat</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T17:13:01.000Z</td>\n",
       "      <td>SHANtell martin</td>\n",
       "      <td>748374</td>\n",
       "      <td>57527</td>\n",
       "      <td>2966</td>\n",
       "      <td>15954</td>\n",
       "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ZAPwfrtAFY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
       "      <td>LastWeekTonight</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T07:30:00.000Z</td>\n",
       "      <td>\"last week tonight trump presidency\"|\"last wee...</td>\n",
       "      <td>2418783</td>\n",
       "      <td>97185</td>\n",
       "      <td>6146</td>\n",
       "      <td>12703</td>\n",
       "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One year after the presidential election, John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5qpjK5DgCt4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
       "      <td>Rudy Mancuso</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T19:05:24.000Z</td>\n",
       "      <td>\"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...</td>\n",
       "      <td>3191434</td>\n",
       "      <td>146033</td>\n",
       "      <td>5339</td>\n",
       "      <td>8181</td>\n",
       "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>WATCH MY PREVIOUS VIDEO  \\n\\nSUBSCRIBE  http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puqaWrEC7tY</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
       "      <td>Good Mythical Morning</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T11:00:04.000Z</td>\n",
       "      <td>\"rhett and link\"|\"gmm\"|\"good mythical morning\"...</td>\n",
       "      <td>343168</td>\n",
       "      <td>10172</td>\n",
       "      <td>666</td>\n",
       "      <td>2146</td>\n",
       "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  2kyS6SvSYSE      17.14.11   \n",
       "1  1ZAPwfrtAFY      17.14.11   \n",
       "2  5qpjK5DgCt4      17.14.11   \n",
       "3  puqaWrEC7tY      17.14.11   \n",
       "\n",
       "                                               title      channel_title_new  \\\n",
       "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
       "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
       "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
       "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
       "\n",
       "  category_id              publish_time  \\\n",
       "0          22  2017-11-13T17:13:01.000Z   \n",
       "1          24  2017-11-13T07:30:00.000Z   \n",
       "2          23  2017-11-12T19:05:24.000Z   \n",
       "3          24  2017-11-13T11:00:04.000Z   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0                                    SHANtell martin   748374   57527   \n",
       "1  \"last week tonight trump presidency\"|\"last wee...  2418783   97185   \n",
       "2  \"racist superman\"|\"rudy\"|\"mancuso\"|\"king\"|\"bac...  3191434  146033   \n",
       "3  \"rhett and link\"|\"gmm\"|\"good mythical morning\"...   343168   10172   \n",
       "\n",
       "  dislikes comment_count                                  thumbnail_link  \\\n",
       "0     2966         15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
       "1     6146         12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
       "2     5339          8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
       "3      666          2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
       "\n",
       "  comments_disabled ratings_disabled video_error_or_removed  \\\n",
       "0             False            False                  False   \n",
       "1             False            False                  False   \n",
       "2             False            False                  False   \n",
       "3             False            False                  False   \n",
       "\n",
       "                                         description  \n",
       "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...  \n",
       "1  One year after the presidential election, John...  \n",
       "2  WATCH MY PREVIOUS VIDEO  \\n\\nSUBSCRIBE  http...  \n",
       "3  Today we find out if Link is a Nickelback amat...  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Rename\n",
    "renamed = df.withColumnRenamed('channel_title','channel_title_new')\n",
    "renamed.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------------+\n",
      "|first_name|last_name|      full_name|\n",
      "+----------+---------+---------------+\n",
      "|   Abraham|  Lincoln|Abraham Lincoln|\n",
      "+----------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import * #IntegerType\n",
    "\n",
    "# Concatenate columns\n",
    "# pyspark.sql.functions.concat_ws(sep, *cols)[source]\n",
    "# Concatenates multiple input string columns together into a single string column, using the given separator.\n",
    "\n",
    "names = spark.createDataFrame([('Abraham','Lincoln')], ['first_name', 'last_name'])\n",
    "names.select(names.first_name,names.last_name,concat_ws(' ', names.first_name, names.last_name).alias('full_name')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting from Date and Timestamp variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+--------------+\n",
      "|trending_date|TRENDING_YEAR|TRENDING_MONTH|\n",
      "+-------------+-------------+--------------+\n",
      "+-------------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract year, month, day etc. from a date field\n",
    "# Other options: dayofmonth, dayofweek, dayofyear, weekofyear\n",
    "import pyspark.sql.functions as fn\n",
    "year = df.withColumn(\"TRENDING_YEAR\",fn.year(\"trending_date\")) \\\n",
    "         .withColumn(\"TRENDING_MONTH\",fn.month(\"trending_date\"))\n",
    "#QA\n",
    "year.filter(\"TRENDING_YEAR=2011\").select(['trending_date','TRENDING_YEAR','TRENDING_MONTH']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|diff|\n",
      "+----+\n",
      "|  32|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference between two dates:\n",
    "# pyspark.sql.functions.datediff(end, start)\n",
    "# Returns the number of days from start to end.\n",
    "\n",
    "date_df = spark.createDataFrame([('2015-04-08','2015-05-10')], ['d1', 'd2'])\n",
    "date_df.select(datediff(date_df.d2, date_df.d1).alias('diff')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting a string around a pattern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|     s|    news|\n",
      "+------+--------+\n",
      "|ab12cd|[ab, cd]|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split a string around pattern (pattern is a regular expression).\n",
    "from pyspark.sql.functions import *\n",
    "# pyspark.sql.functions.split(str, pattern)[source]\n",
    "\n",
    "abc = spark.createDataFrame([('ab12cd',)], ['s',])\n",
    "abc.select(abc.s,split(abc.s, '[0-9]+').alias('news')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arrays**\n",
    "\n",
    "*Note that the array_distinct feature is new in Spark 2.4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array\n",
      "+--------------------+--------------------+\n",
      "|              Monday|             Tuesday|\n",
      "+--------------------+--------------------+\n",
      "|[coffee, milk, co...|[coffee, chocolat...|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "Which customers purchased milk? array_contains\n",
      "+----------------------------+\n",
      "|array_contains(Monday, milk)|\n",
      "+----------------------------+\n",
      "|true                        |\n",
      "+----------------------------+\n",
      "\n",
      "List of unique products purchased on Monday: array_distinct\n",
      "+----------------------+\n",
      "|array_distinct(Monday)|\n",
      "+----------------------+\n",
      "|[coffee, milk]        |\n",
      "+----------------------+\n",
      "\n",
      "What did our customers order on Monday but not Tuesday? array_except\n",
      "+-----------------------------+\n",
      "|array_except(Monday, Tuesday)|\n",
      "+-----------------------------+\n",
      "|[milk]                       |\n",
      "+-----------------------------+\n",
      "\n",
      "What did our customers order on BOTH Monday and Tuesday?: array_intersect\n",
      "+--------------------------------+\n",
      "|array_intersect(Monday, Tuesday)|\n",
      "+--------------------------------+\n",
      "|[coffee]                        |\n",
      "+--------------------------------+\n",
      "\n",
      "All purchases on monday in a string: array_join\n",
      "+---------------------+\n",
      "|array_join(Monday, ,)|\n",
      "+---------------------+\n",
      "|coffee,milk,coffee   |\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Arrays - col/cols  list of column names (string) or list of Column expressions that have the same data type.\n",
    "# pyspark.sql.functions\n",
    "# note this is only available in pyspark 2.4+\n",
    "from pyspark.sql.functions import *\n",
    "#      .array(*cols)   -   Creates a new array column.\n",
    "#      .array_contains(col, value)  - Collection function: returns null if the array is null, true if the array contains the given value, and false otherwise.\n",
    "#      .array_distinct(col) - Collection function: removes duplicate values from the array. :param col: name of column or expression\n",
    "#      .array_except(col1, col2) - Collection function: returns an array of the elements in col1 but not in col2, without duplicates.\n",
    "#      .array_intersect(col1, col2) - Collection function: returns an array of the elements in the intersection of col1 and col2, without duplicates.\n",
    "#      .array_join(col, delimiter, null_replacement=None) - Concatenates the elements of column using the delimiter. Null values are replaced with null_replacement if set, otherwise they are ignored.\n",
    "#      .array_max(col) - Collection function: returns the maximum value of the array.\n",
    "#      .array_min(col) - Collection function: returns the minimum value of the array.\n",
    "#      .array_position(col, value) - Collection function: Locates the position of the first occurrence of the given value in the given array. Returns null if either of the arguments are null.\n",
    "#      .array_remove(col, element)- Collection function: Remove all elements that equal to element from the given array.\n",
    "#      .array_repeat(col, count) - Collection function: creates an array containing a column repeated count times.\n",
    "#      .array_sort(col) - Collection function: sorts the input array in ascending order. The elements of the input array must be orderable. Null elements will be placed at the end of the returned array.\n",
    "#      .array_union(col1, col2) - Collection function: returns an array of the elements in the union of col1 and col2, without duplicates.\n",
    "#      .arrays_overlap(a1, a2) - Collection function: returns true if the arrays contain any common non-null element; if not, returns null if both the arrays are non-empty and any of them contains a null element; returns false otherwise.\n",
    "#      .arrays_zip(*cols)[source] - Collection function: Returns a merged array of structs in which the N-th struct contains all N-th values of input arrays.\n",
    "\n",
    "customer = spark.createDataFrame([('coffee','milk','coffee','coffee','chocolate','')], ['item1', 'item2','item3','item4','item5','item6'])\n",
    "purchases = customer.select(array('item1', 'item2','item3').alias(\"Monday\"),\\\n",
    "                            array('item4', 'item5','item6').alias(\"Tuesday\"))\n",
    "\n",
    "print(\"array\")\n",
    "purchases.show()\n",
    "\n",
    "print(\"Which customers purchased milk? array_contains\")\n",
    "purchases.select(array_contains(purchases.Monday, \"milk\")).show(1, False)\n",
    "\n",
    "print(\"List of unique products purchased on Monday: array_distinct\")\n",
    "purchases.select(array_distinct(purchases.Monday)).show(1, False)\n",
    "\n",
    "print(\"What did our customers order on Monday but not Tuesday? array_except\")\n",
    "purchases.select(array_except(purchases.Monday, purchases.Tuesday)).show(1, False)\n",
    "\n",
    "print(\"What did our customers order on BOTH Monday and Tuesday?: array_intersect\")\n",
    "purchases.select(array_intersect(purchases.Monday, purchases.Tuesday)).show(1, False)\n",
    "\n",
    "print(\"All purchases on monday in a string: array_join\")\n",
    "purchases.select(array_join(purchases.Monday, ',')).show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an array by splitting a string field** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------------+\n",
      "|age|sentence            |array                     |\n",
      "+---+--------------------+--------------------------+\n",
      "|45 |I like to ride bikes|[I, like, to, ride, bikes]|\n",
      "+---+--------------------+--------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "values = [(45,'I like to ride bikes'), \\\n",
    "          (14,'I like chicken'), \\\n",
    "          (63,'I like bubbles'), \\\n",
    "          (75,'I like roller coasters'), \\\n",
    "          (24,'I like shuffle board'), \\\n",
    "          (45,'I like to swim')]\n",
    "sentences = spark.createDataFrame(values,['age', 'sentence'])\n",
    "df = sentences.withColumn(\"array\", split(col(\"sentence\"), \" \"))\n",
    "df.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Functions\n",
    "\n",
    "Functions as you know them in Python work a bit differently in Pyspark because it operates on a cluster. If you define a function the traditional Python way in PySpark, you will not recieve an error message but the call will not distribute on all nodes. So it will run slower. \n",
    "\n",
    "So to convert a Python function to what's called a user defined function (UDF) in PySpark. This is what you do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "|age|age_squared|\n",
      "+---+-----------+\n",
      "| 45|       2025|\n",
      "| 14|        196|\n",
      "| 63|       3969|\n",
      "| 75|       5625|\n",
      "| 24|        576|\n",
      "| 45|       2025|\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def square(x):\n",
    "    return int(x**2)\n",
    "square_udf = udf(lambda z: square(z), IntegerType())\n",
    "\n",
    "df.select('age',square_udf('age').alias('age_squared')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
